{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import seaborn as sns \n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:/CDAC MARCH 2024 AI/PML/assignments/4/')\n",
    "dtest = pd.read_csv(r'test.csv')\n",
    "dtrain = pd.read_csv(r'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "idW = dtrain.groupby('Item_Identifier').Item_Weight.mean()\n",
    "dtrain.shape\n",
    "def fillItemWeight(row):\n",
    "    #print(row['Item_Weight'])\n",
    "    if row['Item_Weight']==np.nan or row['Item_Weight']==None:\n",
    "        #print(row)\n",
    "        row['Item_Weight'] = idW[row['Item_Identifier']]\n",
    "    return row    \n",
    "d_new = dtrain.apply(lambda r: fillItemWeight(r), axis=1)\n",
    "#display(d_new)\n",
    "#d_new.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.300\n",
       "1        5.920\n",
       "2       17.500\n",
       "3       19.200\n",
       "4        8.930\n",
       "         ...  \n",
       "8518     6.865\n",
       "8519     8.380\n",
       "8520    10.600\n",
       "8521     7.210\n",
       "8522    14.800\n",
       "Name: Item_Weight, Length: 8523, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     4\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing means in missing values in item_weight repective to their identifier\n",
    "means = dtrain.groupby('Item_Identifier').Item_Weight.transform('mean')\n",
    "display(means)\n",
    "dtrain['Item_Weight'] = dtrain['Item_Weight'].fillna(means)\n",
    "dtrain.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       20.750\n",
       "1        8.300\n",
       "2       14.600\n",
       "3        7.315\n",
       "4       13.600\n",
       "         ...  \n",
       "5676    10.500\n",
       "5677     7.600\n",
       "5678    10.000\n",
       "5679    15.300\n",
       "5680     9.500\n",
       "Name: Item_Weight, Length: 5681, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                    20\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1606\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing means in missing values in item_weight repective to their identifier\n",
    "means = dtest.groupby('Item_Identifier').Item_Weight.transform('mean')\n",
    "display(means)\n",
    "dtest['Item_Weight'] = dtest['Item_Weight'].fillna(means)\n",
    "dtest.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 11)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1559, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#items_train = dtrain[['Item_Identifier','Item_Weight']].sort_values(by='Item_Identifier')\n",
    "# items_train = dtrain[['Item_Identifier','Item_Weight']]\n",
    "# items_test = dtest[['Item_Identifier','Item_Weight']]\n",
    "# con = pd.concat([items_train, items_test], ignore_index=True, join='inner')\n",
    "\n",
    "\n",
    "con = pd.concat([dtrain[['Item_Identifier','Item_Weight']],dtest[['Item_Identifier','Item_Weight']]], ignore_index=True, join='inner')\n",
    "\n",
    "con.drop_duplicates(inplace=True)\n",
    "con.dropna(inplace=True)\n",
    "display(con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier    0\n",
       "Item_Weight        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight\n",
       "0           FDA15         9.30\n",
       "1           DRC01         5.92\n",
       "2           FDN15        17.50\n",
       "3           FDX07        19.20\n",
       "4           NCD19         8.93"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sort_values(by='Item_Identifier')\n",
    "display(con.isna().sum(axis=0))\n",
    "con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5681, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtrain.drop('Item_Weight', axis=1, inplace=True)\n",
    "#dtrain.dropna(inplace=True)\n",
    "display(dtrain.shape)\n",
    "dtest.drop('Item_Weight', axis=1, inplace=True)\n",
    "display(dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### removing remaining 4\n",
    "dtrain = pd.merge(dtrain,con, on='Item_Identifier')\n",
    "dtest = pd.merge(dtest,con, on='Item_Identifier')\n",
    "display(dtrain.shape)\n",
    "display(dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "Item_Weight                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>250.2092</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>5976.2208</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016019</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>248.5092</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>6474.2392</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.6092</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>5976.2208</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.026818</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>248.9092</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>498.0184</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier Item_Fat_Content  Item_Visibility Item_Type  Item_MRP  \\\n",
       "0           FDA15          Low Fat         0.016047     Dairy  249.8092   \n",
       "1           FDA15          Low Fat         0.016055     Dairy  250.2092   \n",
       "2           FDA15          Low Fat         0.016019     Dairy  248.5092   \n",
       "3           FDA15          Low Fat         0.016088     Dairy  249.6092   \n",
       "4           FDA15          Low Fat         0.026818     Dairy  248.9092   \n",
       "\n",
       "  Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0            OUT049                       1999      Medium   \n",
       "1            OUT045                       2002         NaN   \n",
       "2            OUT035                       2004       Small   \n",
       "3            OUT018                       2009      Medium   \n",
       "4            OUT010                       1998         NaN   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  Item_Weight  \n",
       "0               Tier 1  Supermarket Type1          3735.1380          9.3  \n",
       "1               Tier 2  Supermarket Type1          5976.2208          9.3  \n",
       "2               Tier 2  Supermarket Type1          6474.2392          9.3  \n",
       "3               Tier 3  Supermarket Type2          5976.2208          9.3  \n",
       "4               Tier 3      Grocery Store           498.0184          9.3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1606\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Weight                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>104.4622</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.0622</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>105.9622</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>105.8622</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier Item_Fat_Content  Item_Visibility    Item_Type  Item_MRP  \\\n",
       "0           FDW58          Low Fat         0.007565  Snack Foods  107.8622   \n",
       "1           FDW58          Low Fat         0.007596  Snack Foods  104.4622   \n",
       "2           FDW58          Low Fat         0.007584  Snack Foods  107.0622   \n",
       "3           FDW58          Low Fat         0.000000  Snack Foods  105.9622   \n",
       "4           FDW58          Low Fat         0.007568  Snack Foods  105.8622   \n",
       "\n",
       "  Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0            OUT049                       1999      Medium   \n",
       "1            OUT017                       2007         NaN   \n",
       "2            OUT018                       2009      Medium   \n",
       "3            OUT046                       1997       Small   \n",
       "4            OUT045                       2002         NaN   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  Item_Weight  \n",
       "0               Tier 1  Supermarket Type1        20.75  \n",
       "1               Tier 2  Supermarket Type1        20.75  \n",
       "2               Tier 3  Supermarket Type2        20.75  \n",
       "3               Tier 1  Supermarket Type1        20.75  \n",
       "4               Tier 2  Supermarket Type1        20.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dtrain.isna().sum(axis=0))\n",
    "display(dtrain.head())\n",
    "display(dtest.isna().sum(axis=0))\n",
    "display(dtest.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For outlet_size missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>OUT019</td>\n",
       "      <td>1985</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Grocery Store</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0               OUT010                       1998         NaN   \n",
       "555             OUT013                       1987        High   \n",
       "1487            OUT017                       2007         NaN   \n",
       "2413            OUT018                       2009      Medium   \n",
       "3341            OUT019                       1985       Small   \n",
       "\n",
       "     Outlet_Location_Type        Outlet_Type  \n",
       "0                  Tier 3      Grocery Store  \n",
       "555                Tier 3  Supermarket Type1  \n",
       "1487               Tier 2  Supermarket Type1  \n",
       "2413               Tier 3  Supermarket Type2  \n",
       "3341               Tier 1      Grocery Store  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outlet_train = dtrain[['Outlet_Identifier', 'Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type','Outlet_Type']].sort_values(by='Outlet_Identifier')\n",
    "outlet_test = dtest[['Outlet_Identifier', 'Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type','Outlet_Type']].sort_values(by='Outlet_Identifier')\n",
    "con  = pd.concat([outlet_train, outlet_test], join='inner', ignore_index=True)\n",
    "con.drop_duplicates(inplace=True)\n",
    "#con.dropna(inplace=True)\n",
    "display(con.shape)\n",
    "display(con.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dtrain.drop(['Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type','Outlet_Type'], axis=1, inplace=True)\n",
    "dtrain = pd.merge(dtrain,con, on='Outlet_Identifier')\n",
    "display(dtrain.shape)\n",
    "\n",
    "dtest.drop(['Outlet_Establishment_Year','Outlet_Size','Outlet_Location_Type','Outlet_Type'], axis=1, inplace=True)\n",
    "dtest = pd.merge(dtest,con, on='Outlet_Identifier')\n",
    "display(dtest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain.isna().sum(axis=0)\n",
    "dtrain['Outlet_Size'].fillna(value='Small', inplace=True)\n",
    "dtest['Outlet_Size'].fillna(value='Small', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>184.4950</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>4028.0900</td>\n",
       "      <td>19.20</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>LF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.2614</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>552.6140</td>\n",
       "      <td>8.93</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDP10</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.128289</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>104.9622</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1164.4842</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0           FDA15          Low Fat         0.016047                  Dairy   \n",
       "1           FDN15          Low Fat         0.016760                   Meat   \n",
       "2           FDX07          Regular         0.022954  Fruits and Vegetables   \n",
       "3           NCD19               LF         0.000000              Household   \n",
       "4           FDP10          Low Fat         0.128289            Snack Foods   \n",
       "\n",
       "   Item_MRP Outlet_Identifier  Item_Outlet_Sales  Item_Weight  \\\n",
       "0  249.8092            OUT049          3735.1380         9.30   \n",
       "1  141.6180            OUT049          2097.2700        17.50   \n",
       "2  184.4950            OUT049          4028.0900        19.20   \n",
       "3   53.2614            OUT049           552.6140         8.93   \n",
       "4  104.9622            OUT049          1164.4842        19.00   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       1999      Medium               Tier 1   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1999      Medium               Tier 1   \n",
       "4                       1999      Medium               Tier 1   \n",
       "\n",
       "         Outlet_Type  \n",
       "0  Supermarket Type1  \n",
       "1  Supermarket Type1  \n",
       "2  Supermarket Type1  \n",
       "3  Supermarket Type1  \n",
       "4  Supermarket Type1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dtrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regular</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>184.4950</td>\n",
       "      <td>4028.0900</td>\n",
       "      <td>19.20</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.2614</td>\n",
       "      <td>552.6140</td>\n",
       "      <td>8.93</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.128289</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>104.9622</td>\n",
       "      <td>1164.4842</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Fat_Content  Item_Visibility              Item_Type  Item_MRP  \\\n",
       "0          Low Fat         0.016047                  Dairy  249.8092   \n",
       "1          Low Fat         0.016760                   Meat  141.6180   \n",
       "2          Regular         0.022954  Fruits and Vegetables  184.4950   \n",
       "3               LF         0.000000              Household   53.2614   \n",
       "4          Low Fat         0.128289            Snack Foods  104.9622   \n",
       "\n",
       "   Item_Outlet_Sales  Item_Weight  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0          3735.1380         9.30                       1999      Medium   \n",
       "1          2097.2700        17.50                       1999      Medium   \n",
       "2          4028.0900        19.20                       1999      Medium   \n",
       "3           552.6140         8.93                       1999      Medium   \n",
       "4          1164.4842        19.00                       1999      Medium   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  \n",
       "0               Tier 1  Supermarket Type1  \n",
       "1               Tier 1  Supermarket Type1  \n",
       "2               Tier 1  Supermarket Type1  \n",
       "3               Tier 1  Supermarket Type1  \n",
       "4               Tier 1  Supermarket Type1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>20.750</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regular</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>85.9198</td>\n",
       "      <td>8.300</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>83.4592</td>\n",
       "      <td>9.195</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>184.1924</td>\n",
       "      <td>5.985</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.092738</td>\n",
       "      <td>Breads</td>\n",
       "      <td>122.3098</td>\n",
       "      <td>4.785</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Fat_Content  Item_Visibility     Item_Type  Item_MRP  Item_Weight  \\\n",
       "0          Low Fat         0.007565   Snack Foods  107.8622       20.750   \n",
       "1          Regular         0.038271         Dairy   85.9198        8.300   \n",
       "2          Low Fat         0.015884  Baking Goods   83.4592        9.195   \n",
       "3          Low Fat         0.005675  Baking Goods  184.1924        5.985   \n",
       "4          Low Fat         0.092738        Breads  122.3098        4.785   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       1999      Medium               Tier 1   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1999      Medium               Tier 1   \n",
       "4                       1999      Medium               Tier 1   \n",
       "\n",
       "         Outlet_Type  \n",
       "0  Supermarket Type1  \n",
       "1  Supermarket Type1  \n",
       "2  Supermarket Type1  \n",
       "3  Supermarket Type1  \n",
       "4  Supermarket Type1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = dtrain.drop(['Item_Identifier','Outlet_Identifier'], axis=1)\n",
    "display(X_train.head())\n",
    "X_test = dtest.drop(['Item_Identifier','Outlet_Identifier'],  axis=1)\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['Item_Outlet_Sales']\n",
    "X_train = X_train.drop('Item_Outlet_Sales',axis=1)\n",
    "X_test = dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc = OneHotEncoder(sparse_output=False)\n",
    "mk = make_column_transformer((ohc, make_column_selector(dtype_include=object)), (\"passthrough\",make_column_selector(dtype_include=['int64','float64'])),verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "X_train = mk.fit_transform(X_train)\n",
    "X_test = mk.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1076.7067056682704\n",
      "{'learning_rate': 0.10888888888888888, 'max_depth': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "############################ Regression with catboost ###################################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "cbgm = CatBoostRegressor(random_state=24, logging_level='Silent')\n",
    "params = {\"max_depth\":[None, 2, 3, 4],\n",
    "              \"n_estimators\": [25, 50, 100],\n",
    "              \"learning_rate\": np.linspace(0.01, 0.9, 10)}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "#param = {\"alpha\": np.linspace(0.001,5,10),\"l1_ratio\":np.linspace(0.1,0.9,9)}\n",
    "\n",
    "gcv_cat = GridSearchCV(cbgm,cv = kfold, param_grid=params,scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "gcv_cat.fit(X_train,y_train)\n",
    "print(gcv_cat.best_score_)\n",
    "print(gcv_cat.best_params_)\n",
    "#cbgm.fit(X_train,y_train)\n",
    "y_pred = gcv_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred < 0] =0\n",
    "df = pd.DataFrame({'Item_Identifier':dtest['Item_Identifier'], 'Outlet_Identifier': dtest['Outlet_Identifier'], 'Item_Outlet_Sales':y_pred})\n",
    "df.to_csv(r'D:/CDAC MARCH 2024 AI/PML/assignments/4/submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain.isna().sum(axis=0)\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('OUT013', 'High'), ('OUT018', 'Medium'), ('OUT019', 'Small'),\n",
       "       ('OUT027', 'Medium'), ('OUT035', 'Small'), ('OUT046', 'Small'),\n",
       "       ('OUT049', 'Medium')], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'OUT013': 'High',\n",
       " 'OUT018': 'Medium',\n",
       " 'OUT019': 'Small',\n",
       " 'OUT027': 'Medium',\n",
       " 'OUT035': 'Small',\n",
       " 'OUT046': 'Small',\n",
       " 'OUT049': 'Medium'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.groupby('Outlet_Identifier').Outlet_Size.value_counts().index.values\n",
    "max = dict(max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outlet_Identifier\n",
       "OUT010       NaN\n",
       "OUT013      High\n",
       "OUT017       NaN\n",
       "OUT018    Medium\n",
       "OUT019     Small\n",
       "OUT027    Medium\n",
       "OUT035     Small\n",
       "OUT045       NaN\n",
       "OUT046     Small\n",
       "OUT049    Medium\n",
       "Name: Outlet_Size, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.groupby('Outlet_Identifier').Outlet_Size.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       NaN\n",
       "28      NaN\n",
       "30      NaN\n",
       "45      NaN\n",
       "65      NaN\n",
       "       ... \n",
       "8400    NaN\n",
       "8432    NaN\n",
       "8473    NaN\n",
       "8486    NaN\n",
       "8509    NaN\n",
       "Name: Outlet_Size, Length: 555, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain[dtrain['Outlet_Identifier']=='OUT010'].Outlet_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     4\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing means in missing values in outlet_size repective to their identifier\n",
    "# max = dtrain.groupby('Outlet_Identifier').Outlet_Size.transform('max')\n",
    "# display(max)\n",
    "# dtrain['Outlet_Size'] = dtrain['Outlet_Size'].fillna(dtrain['Outlet_Identifier'].map(max))\n",
    "# dtrain.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9.300\n",
       "1        5.920\n",
       "2       17.500\n",
       "3       19.200\n",
       "4        8.930\n",
       "         ...  \n",
       "8518     6.865\n",
       "8519     8.380\n",
       "8520    10.600\n",
       "8521     7.210\n",
       "8522    14.800\n",
       "Name: Item_Weight, Length: 8523, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     4\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing means in missing values in item_weight repective to their identifier\n",
    "# means = dtrain.groupby('Item_Identifier').Item_Weight.transform('mean')\n",
    "# display(means)\n",
    "# dtrain['Item_Weight'] = dtrain['Item_Weight'].fillna(means)\n",
    "# dtrain.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing means in missing values in outlet_size repective to their identifier\n",
    "# means = dtrain.groupby('Outlet_Identifier').Item_Weight.transform('mean')\n",
    "# display(means)\n",
    "# dtrain['Outlet_Size'] = dtrain['Outlet_Size'].fillna(means)\n",
    "# dtrain.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dtrain.shape)\n",
    "dt = dtrain.drop_duplicates()\n",
    "display(dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0         9.30          Low Fat         0.016047                  Dairy   \n",
       "1         5.92          Regular         0.019278            Soft Drinks   \n",
       "2        17.50          Low Fat         0.016760                   Meat   \n",
       "3        19.20          Regular         0.000000  Fruits and Vegetables   \n",
       "4         8.93          Low Fat         0.000000              Household   \n",
       "\n",
       "   Item_MRP  Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0  249.8092                       1999      Medium               Tier 1   \n",
       "1   48.2692                       2009      Medium               Tier 3   \n",
       "2  141.6180                       1999      Medium               Tier 1   \n",
       "3  182.0950                       1998         NaN               Tier 3   \n",
       "4   53.8614                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.drop(['Item_Identifier','Outlet_Identifier'], inplace=True, axis=1)\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.750</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.300</td>\n",
       "      <td>reg</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.600</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>Others</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.315</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight Item_Fat_Content  Item_Visibility    Item_Type  Item_MRP  \\\n",
       "0       20.750          Low Fat         0.007565  Snack Foods  107.8622   \n",
       "1        8.300              reg         0.038428        Dairy   87.3198   \n",
       "2       14.600          Low Fat         0.099575       Others  241.7538   \n",
       "3        7.315          Low Fat         0.015388  Snack Foods  155.0340   \n",
       "4          NaN          Regular         0.118599        Dairy  234.2300   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2007         NaN               Tier 2   \n",
       "2                       1998         NaN               Tier 3   \n",
       "3                       2007         NaN               Tier 2   \n",
       "4                       1985      Medium               Tier 3   \n",
       "\n",
       "         Outlet_Type  \n",
       "0  Supermarket Type1  \n",
       "1  Supermarket Type1  \n",
       "2      Grocery Store  \n",
       "3  Supermarket Type1  \n",
       "4  Supermarket Type3  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dtest.drop(['Item_Identifier','Outlet_Identifier'], inplace=True, axis=1)\n",
    "dtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = dtrain['Item_Outlet_Sales']\n",
    "X_train = dtrain.drop('Item_Outlet_Sales',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_num = SimpleImputer(strategy='mean').set_output(transform='pandas')\n",
    "imp_cat = SimpleImputer(strategy='most_frequent').set_output(transform='pandas')\n",
    "mc = make_column_transformer((imp_num, make_column_selector(dtype_include=[np.number])),(imp_cat,make_column_selector(dtype_include=object)),\n",
    "                             verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "X_train = mc.fit_transform(X_train)\n",
    "X_test = mc.transform(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding \n",
    "ohc = OneHotEncoder(sparse_output=False)\n",
    "mk = make_column_transformer((ohc, make_column_selector(dtype_include=object)), (\"passthrough\",make_column_selector(dtype_include=['int64','float64'])),verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "X_train = mk.fit_transform(X_train)\n",
    "X_test = mk.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content_LF</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Fat_Content_low fat</th>\n",
       "      <th>Item_Fat_Content_reg</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.300</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.920</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.500</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.865</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.380</td>\n",
       "      <td>0.046982</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.600</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.210</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.800</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Fat_Content_LF  Item_Fat_Content_Low Fat  Item_Fat_Content_Regular  \\\n",
       "0                     0.0                       1.0                       0.0   \n",
       "1                     0.0                       0.0                       1.0   \n",
       "2                     0.0                       1.0                       0.0   \n",
       "3                     0.0                       0.0                       1.0   \n",
       "4                     0.0                       1.0                       0.0   \n",
       "...                   ...                       ...                       ...   \n",
       "8518                  0.0                       1.0                       0.0   \n",
       "8519                  0.0                       0.0                       1.0   \n",
       "8520                  0.0                       1.0                       0.0   \n",
       "8521                  0.0                       0.0                       1.0   \n",
       "8522                  0.0                       1.0                       0.0   \n",
       "\n",
       "      Item_Fat_Content_low fat  Item_Fat_Content_reg  Item_Type_Baking Goods  \\\n",
       "0                          0.0                   0.0                     0.0   \n",
       "1                          0.0                   0.0                     0.0   \n",
       "2                          0.0                   0.0                     0.0   \n",
       "3                          0.0                   0.0                     0.0   \n",
       "4                          0.0                   0.0                     0.0   \n",
       "...                        ...                   ...                     ...   \n",
       "8518                       0.0                   0.0                     0.0   \n",
       "8519                       0.0                   0.0                     1.0   \n",
       "8520                       0.0                   0.0                     0.0   \n",
       "8521                       0.0                   0.0                     0.0   \n",
       "8522                       0.0                   0.0                     0.0   \n",
       "\n",
       "      Item_Type_Breads  Item_Type_Breakfast  Item_Type_Canned  \\\n",
       "0                  0.0                  0.0               0.0   \n",
       "1                  0.0                  0.0               0.0   \n",
       "2                  0.0                  0.0               0.0   \n",
       "3                  0.0                  0.0               0.0   \n",
       "4                  0.0                  0.0               0.0   \n",
       "...                ...                  ...               ...   \n",
       "8518               0.0                  0.0               0.0   \n",
       "8519               0.0                  0.0               0.0   \n",
       "8520               0.0                  0.0               0.0   \n",
       "8521               0.0                  0.0               0.0   \n",
       "8522               0.0                  0.0               0.0   \n",
       "\n",
       "      Item_Type_Dairy  ...  Outlet_Location_Type_Tier 2  \\\n",
       "0                 1.0  ...                          0.0   \n",
       "1                 0.0  ...                          0.0   \n",
       "2                 0.0  ...                          0.0   \n",
       "3                 0.0  ...                          0.0   \n",
       "4                 0.0  ...                          0.0   \n",
       "...               ...  ...                          ...   \n",
       "8518              0.0  ...                          0.0   \n",
       "8519              0.0  ...                          1.0   \n",
       "8520              0.0  ...                          1.0   \n",
       "8521              0.0  ...                          0.0   \n",
       "8522              0.0  ...                          0.0   \n",
       "\n",
       "      Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             1.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             1.0                        1.0   \n",
       "4                             1.0                        0.0   \n",
       "...                           ...                        ...   \n",
       "8518                          1.0                        0.0   \n",
       "8519                          0.0                        0.0   \n",
       "8520                          0.0                        0.0   \n",
       "8521                          1.0                        0.0   \n",
       "8522                          0.0                        0.0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                               1.0                            0.0   \n",
       "1                               0.0                            1.0   \n",
       "2                               1.0                            0.0   \n",
       "3                               0.0                            0.0   \n",
       "4                               1.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "8518                            1.0                            0.0   \n",
       "8519                            1.0                            0.0   \n",
       "8520                            1.0                            0.0   \n",
       "8521                            0.0                            1.0   \n",
       "8522                            1.0                            0.0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type3  Item_Weight  Item_Visibility  Item_MRP  \\\n",
       "0                               0.0        9.300         0.016047  249.8092   \n",
       "1                               0.0        5.920         0.019278   48.2692   \n",
       "2                               0.0       17.500         0.016760  141.6180   \n",
       "3                               0.0       19.200         0.000000  182.0950   \n",
       "4                               0.0        8.930         0.000000   53.8614   \n",
       "...                             ...          ...              ...       ...   \n",
       "8518                            0.0        6.865         0.056783  214.5218   \n",
       "8519                            0.0        8.380         0.046982  108.1570   \n",
       "8520                            0.0       10.600         0.035186   85.1224   \n",
       "8521                            0.0        7.210         0.145221  103.1332   \n",
       "8522                            0.0       14.800         0.044878   75.4670   \n",
       "\n",
       "      Outlet_Establishment_Year  \n",
       "0                        1999.0  \n",
       "1                        2009.0  \n",
       "2                        1999.0  \n",
       "3                        1998.0  \n",
       "4                        1987.0  \n",
       "...                         ...  \n",
       "8518                     1987.0  \n",
       "8519                     2002.0  \n",
       "8520                     2004.0  \n",
       "8521                     2009.0  \n",
       "8522                     1997.0  \n",
       "\n",
       "[8523 rows x 35 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content_LF</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Fat_Content_low fat</th>\n",
       "      <th>Item_Fat_Content_reg</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.315000</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.857645</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5676</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>141.3154</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.142991</td>\n",
       "      <td>169.1448</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>118.7440</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>214.6218</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.104720</td>\n",
       "      <td>79.7960</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Fat_Content_LF  Item_Fat_Content_Low Fat  Item_Fat_Content_Regular  \\\n",
       "0                     0.0                       1.0                       0.0   \n",
       "1                     0.0                       0.0                       0.0   \n",
       "2                     0.0                       1.0                       0.0   \n",
       "3                     0.0                       1.0                       0.0   \n",
       "4                     0.0                       0.0                       1.0   \n",
       "...                   ...                       ...                       ...   \n",
       "5676                  0.0                       0.0                       1.0   \n",
       "5677                  0.0                       0.0                       1.0   \n",
       "5678                  0.0                       1.0                       0.0   \n",
       "5679                  0.0                       0.0                       1.0   \n",
       "5680                  0.0                       0.0                       1.0   \n",
       "\n",
       "      Item_Fat_Content_low fat  Item_Fat_Content_reg  Item_Type_Baking Goods  \\\n",
       "0                          0.0                   0.0                     0.0   \n",
       "1                          0.0                   1.0                     0.0   \n",
       "2                          0.0                   0.0                     0.0   \n",
       "3                          0.0                   0.0                     0.0   \n",
       "4                          0.0                   0.0                     0.0   \n",
       "...                        ...                   ...                     ...   \n",
       "5676                       0.0                   0.0                     0.0   \n",
       "5677                       0.0                   0.0                     0.0   \n",
       "5678                       0.0                   0.0                     0.0   \n",
       "5679                       0.0                   0.0                     0.0   \n",
       "5680                       0.0                   0.0                     0.0   \n",
       "\n",
       "      Item_Type_Breads  Item_Type_Breakfast  Item_Type_Canned  \\\n",
       "0                  0.0                  0.0               0.0   \n",
       "1                  0.0                  0.0               0.0   \n",
       "2                  0.0                  0.0               0.0   \n",
       "3                  0.0                  0.0               0.0   \n",
       "4                  0.0                  0.0               0.0   \n",
       "...                ...                  ...               ...   \n",
       "5676               0.0                  0.0               0.0   \n",
       "5677               0.0                  0.0               0.0   \n",
       "5678               0.0                  0.0               0.0   \n",
       "5679               0.0                  0.0               1.0   \n",
       "5680               0.0                  0.0               1.0   \n",
       "\n",
       "      Item_Type_Dairy  ...  Outlet_Location_Type_Tier 2  \\\n",
       "0                 0.0  ...                          0.0   \n",
       "1                 1.0  ...                          1.0   \n",
       "2                 0.0  ...                          0.0   \n",
       "3                 0.0  ...                          1.0   \n",
       "4                 1.0  ...                          0.0   \n",
       "...               ...  ...                          ...   \n",
       "5676              0.0  ...                          0.0   \n",
       "5677              0.0  ...                          0.0   \n",
       "5678              0.0  ...                          1.0   \n",
       "5679              0.0  ...                          1.0   \n",
       "5680              0.0  ...                          1.0   \n",
       "\n",
       "      Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             1.0                        1.0   \n",
       "3                             0.0                        0.0   \n",
       "4                             1.0                        0.0   \n",
       "...                           ...                        ...   \n",
       "5676                          0.0                        0.0   \n",
       "5677                          1.0                        0.0   \n",
       "5678                          0.0                        0.0   \n",
       "5679                          0.0                        0.0   \n",
       "5680                          0.0                        0.0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                               1.0                            0.0   \n",
       "1                               1.0                            0.0   \n",
       "2                               0.0                            0.0   \n",
       "3                               1.0                            0.0   \n",
       "4                               0.0                            0.0   \n",
       "...                             ...                            ...   \n",
       "5676                            1.0                            0.0   \n",
       "5677                            0.0                            1.0   \n",
       "5678                            1.0                            0.0   \n",
       "5679                            1.0                            0.0   \n",
       "5680                            1.0                            0.0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type3  Item_Weight  Item_Visibility  Item_MRP  \\\n",
       "0                               0.0    20.750000         0.007565  107.8622   \n",
       "1                               0.0     8.300000         0.038428   87.3198   \n",
       "2                               0.0    14.600000         0.099575  241.7538   \n",
       "3                               0.0     7.315000         0.015388  155.0340   \n",
       "4                               1.0    12.857645         0.118599  234.2300   \n",
       "...                             ...          ...              ...       ...   \n",
       "5676                            0.0    10.500000         0.013496  141.3154   \n",
       "5677                            0.0     7.600000         0.142991  169.1448   \n",
       "5678                            0.0    10.000000         0.073529  118.7440   \n",
       "5679                            0.0    15.300000         0.000000  214.6218   \n",
       "5680                            0.0     9.500000         0.104720   79.7960   \n",
       "\n",
       "      Outlet_Establishment_Year  \n",
       "0                        1999.0  \n",
       "1                        2007.0  \n",
       "2                        1998.0  \n",
       "3                        2007.0  \n",
       "4                        1985.0  \n",
       "...                         ...  \n",
       "5676                     1997.0  \n",
       "5677                     2009.0  \n",
       "5678                     2002.0  \n",
       "5679                     2007.0  \n",
       "5680                     2002.0  \n",
       "\n",
       "[5681 rows x 35 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3735.1380\n",
       "1        443.4228\n",
       "2       2097.2700\n",
       "3        732.3800\n",
       "4        994.7052\n",
       "          ...    \n",
       "8518    2778.3834\n",
       "8519     549.2850\n",
       "8520    1193.1136\n",
       "8521    1845.5976\n",
       "8522     765.6700\n",
       "Name: Item_Outlet_Sales, Length: 8523, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 1/5; 1/120] START learning_rate=0.01, max_depth=None, n_estimators=25.......\n",
      "[CV 1/5; 1/120] END learning_rate=0.01, max_depth=None, n_estimators=25;, score=-1457.074 total time=   0.2s\n",
      "[CV 2/5; 1/120] START learning_rate=0.01, max_depth=None, n_estimators=25.......\n",
      "[CV 2/5; 1/120] END learning_rate=0.01, max_depth=None, n_estimators=25;, score=-1515.521 total time=   0.2s\n",
      "[CV 3/5; 1/120] START learning_rate=0.01, max_depth=None, n_estimators=25.......\n",
      "[CV 3/5; 1/120] END learning_rate=0.01, max_depth=None, n_estimators=25;, score=-1475.028 total time=   0.1s\n",
      "[CV 4/5; 1/120] START learning_rate=0.01, max_depth=None, n_estimators=25.......\n",
      "[CV 4/5; 1/120] END learning_rate=0.01, max_depth=None, n_estimators=25;, score=-1507.782 total time=   0.2s\n",
      "[CV 5/5; 1/120] START learning_rate=0.01, max_depth=None, n_estimators=25.......\n",
      "[CV 5/5; 1/120] END learning_rate=0.01, max_depth=None, n_estimators=25;, score=-1571.859 total time=   0.2s\n",
      "[CV 1/5; 2/120] START learning_rate=0.01, max_depth=None, n_estimators=50.......\n",
      "[CV 1/5; 2/120] END learning_rate=0.01, max_depth=None, n_estimators=50;, score=-1319.744 total time=   0.2s\n",
      "[CV 2/5; 2/120] START learning_rate=0.01, max_depth=None, n_estimators=50.......\n",
      "[CV 2/5; 2/120] END learning_rate=0.01, max_depth=None, n_estimators=50;, score=-1371.884 total time=   0.2s\n",
      "[CV 3/5; 2/120] START learning_rate=0.01, max_depth=None, n_estimators=50.......\n",
      "[CV 3/5; 2/120] END learning_rate=0.01, max_depth=None, n_estimators=50;, score=-1331.566 total time=   0.2s\n",
      "[CV 4/5; 2/120] START learning_rate=0.01, max_depth=None, n_estimators=50.......\n",
      "[CV 4/5; 2/120] END learning_rate=0.01, max_depth=None, n_estimators=50;, score=-1364.759 total time=   0.2s\n",
      "[CV 5/5; 2/120] START learning_rate=0.01, max_depth=None, n_estimators=50.......\n",
      "[CV 5/5; 2/120] END learning_rate=0.01, max_depth=None, n_estimators=50;, score=-1436.324 total time=   0.2s\n",
      "[CV 1/5; 3/120] START learning_rate=0.01, max_depth=None, n_estimators=100......\n",
      "[CV 1/5; 3/120] END learning_rate=0.01, max_depth=None, n_estimators=100;, score=-1162.526 total time=   0.4s\n",
      "[CV 2/5; 3/120] START learning_rate=0.01, max_depth=None, n_estimators=100......\n",
      "[CV 2/5; 3/120] END learning_rate=0.01, max_depth=None, n_estimators=100;, score=-1205.158 total time=   0.4s\n",
      "[CV 3/5; 3/120] START learning_rate=0.01, max_depth=None, n_estimators=100......\n",
      "[CV 3/5; 3/120] END learning_rate=0.01, max_depth=None, n_estimators=100;, score=-1169.705 total time=   0.4s\n",
      "[CV 4/5; 3/120] START learning_rate=0.01, max_depth=None, n_estimators=100......\n",
      "[CV 4/5; 3/120] END learning_rate=0.01, max_depth=None, n_estimators=100;, score=-1199.722 total time=   0.4s\n",
      "[CV 5/5; 3/120] START learning_rate=0.01, max_depth=None, n_estimators=100......\n",
      "[CV 5/5; 3/120] END learning_rate=0.01, max_depth=None, n_estimators=100;, score=-1274.059 total time=   0.4s\n",
      "[CV 1/5; 4/120] START learning_rate=0.01, max_depth=2, n_estimators=25..........\n",
      "[CV 1/5; 4/120] END learning_rate=0.01, max_depth=2, n_estimators=25;, score=-1503.983 total time=   0.1s\n",
      "[CV 2/5; 4/120] START learning_rate=0.01, max_depth=2, n_estimators=25..........\n",
      "[CV 2/5; 4/120] END learning_rate=0.01, max_depth=2, n_estimators=25;, score=-1563.349 total time=   0.1s\n",
      "[CV 3/5; 4/120] START learning_rate=0.01, max_depth=2, n_estimators=25..........\n",
      "[CV 3/5; 4/120] END learning_rate=0.01, max_depth=2, n_estimators=25;, score=-1530.973 total time=   0.1s\n",
      "[CV 4/5; 4/120] START learning_rate=0.01, max_depth=2, n_estimators=25..........\n",
      "[CV 4/5; 4/120] END learning_rate=0.01, max_depth=2, n_estimators=25;, score=-1559.503 total time=   0.1s\n",
      "[CV 5/5; 4/120] START learning_rate=0.01, max_depth=2, n_estimators=25..........\n",
      "[CV 5/5; 4/120] END learning_rate=0.01, max_depth=2, n_estimators=25;, score=-1616.106 total time=   0.1s\n",
      "[CV 1/5; 5/120] START learning_rate=0.01, max_depth=2, n_estimators=50..........\n",
      "[CV 1/5; 5/120] END learning_rate=0.01, max_depth=2, n_estimators=50;, score=-1397.778 total time=   0.1s\n",
      "[CV 2/5; 5/120] START learning_rate=0.01, max_depth=2, n_estimators=50..........\n",
      "[CV 2/5; 5/120] END learning_rate=0.01, max_depth=2, n_estimators=50;, score=-1455.692 total time=   0.1s\n",
      "[CV 3/5; 5/120] START learning_rate=0.01, max_depth=2, n_estimators=50..........\n",
      "[CV 3/5; 5/120] END learning_rate=0.01, max_depth=2, n_estimators=50;, score=-1425.193 total time=   0.1s\n",
      "[CV 4/5; 5/120] START learning_rate=0.01, max_depth=2, n_estimators=50..........\n",
      "[CV 4/5; 5/120] END learning_rate=0.01, max_depth=2, n_estimators=50;, score=-1453.152 total time=   0.2s\n",
      "[CV 5/5; 5/120] START learning_rate=0.01, max_depth=2, n_estimators=50..........\n",
      "[CV 5/5; 5/120] END learning_rate=0.01, max_depth=2, n_estimators=50;, score=-1514.497 total time=   0.1s\n",
      "[CV 1/5; 6/120] START learning_rate=0.01, max_depth=2, n_estimators=100.........\n",
      "[CV 1/5; 6/120] END learning_rate=0.01, max_depth=2, n_estimators=100;, score=-1257.392 total time=   0.2s\n",
      "[CV 2/5; 6/120] START learning_rate=0.01, max_depth=2, n_estimators=100.........\n",
      "[CV 2/5; 6/120] END learning_rate=0.01, max_depth=2, n_estimators=100;, score=-1310.151 total time=   0.2s\n",
      "[CV 3/5; 6/120] START learning_rate=0.01, max_depth=2, n_estimators=100.........\n",
      "[CV 3/5; 6/120] END learning_rate=0.01, max_depth=2, n_estimators=100;, score=-1280.952 total time=   0.2s\n",
      "[CV 4/5; 6/120] START learning_rate=0.01, max_depth=2, n_estimators=100.........\n",
      "[CV 4/5; 6/120] END learning_rate=0.01, max_depth=2, n_estimators=100;, score=-1309.013 total time=   0.2s\n",
      "[CV 5/5; 6/120] START learning_rate=0.01, max_depth=2, n_estimators=100.........\n",
      "[CV 5/5; 6/120] END learning_rate=0.01, max_depth=2, n_estimators=100;, score=-1375.381 total time=   0.2s\n",
      "[CV 1/5; 7/120] START learning_rate=0.01, max_depth=3, n_estimators=25..........\n",
      "[CV 1/5; 7/120] END learning_rate=0.01, max_depth=3, n_estimators=25;, score=-1478.789 total time=   0.1s\n",
      "[CV 2/5; 7/120] START learning_rate=0.01, max_depth=3, n_estimators=25..........\n",
      "[CV 2/5; 7/120] END learning_rate=0.01, max_depth=3, n_estimators=25;, score=-1536.845 total time=   0.1s\n",
      "[CV 3/5; 7/120] START learning_rate=0.01, max_depth=3, n_estimators=25..........\n",
      "[CV 3/5; 7/120] END learning_rate=0.01, max_depth=3, n_estimators=25;, score=-1500.231 total time=   0.1s\n",
      "[CV 4/5; 7/120] START learning_rate=0.01, max_depth=3, n_estimators=25..........\n",
      "[CV 4/5; 7/120] END learning_rate=0.01, max_depth=3, n_estimators=25;, score=-1529.672 total time=   0.1s\n",
      "[CV 5/5; 7/120] START learning_rate=0.01, max_depth=3, n_estimators=25..........\n",
      "[CV 5/5; 7/120] END learning_rate=0.01, max_depth=3, n_estimators=25;, score=-1595.478 total time=   0.1s\n",
      "[CV 1/5; 8/120] START learning_rate=0.01, max_depth=3, n_estimators=50..........\n",
      "[CV 1/5; 8/120] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=-1353.690 total time=   0.2s\n",
      "[CV 2/5; 8/120] START learning_rate=0.01, max_depth=3, n_estimators=50..........\n",
      "[CV 2/5; 8/120] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=-1407.112 total time=   0.2s\n",
      "[CV 3/5; 8/120] START learning_rate=0.01, max_depth=3, n_estimators=50..........\n",
      "[CV 3/5; 8/120] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=-1373.052 total time=   0.2s\n",
      "[CV 4/5; 8/120] START learning_rate=0.01, max_depth=3, n_estimators=50..........\n",
      "[CV 4/5; 8/120] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=-1401.599 total time=   0.2s\n",
      "[CV 5/5; 8/120] START learning_rate=0.01, max_depth=3, n_estimators=50..........\n",
      "[CV 5/5; 8/120] END learning_rate=0.01, max_depth=3, n_estimators=50;, score=-1474.606 total time=   0.1s\n",
      "[CV 1/5; 9/120] START learning_rate=0.01, max_depth=3, n_estimators=100.........\n",
      "[CV 1/5; 9/120] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-1201.366 total time=   0.2s\n",
      "[CV 2/5; 9/120] START learning_rate=0.01, max_depth=3, n_estimators=100.........\n",
      "[CV 2/5; 9/120] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-1247.011 total time=   0.2s\n",
      "[CV 3/5; 9/120] START learning_rate=0.01, max_depth=3, n_estimators=100.........\n",
      "[CV 3/5; 9/120] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-1217.738 total time=   0.2s\n",
      "[CV 4/5; 9/120] START learning_rate=0.01, max_depth=3, n_estimators=100.........\n",
      "[CV 4/5; 9/120] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-1246.181 total time=   0.3s\n",
      "[CV 5/5; 9/120] START learning_rate=0.01, max_depth=3, n_estimators=100.........\n",
      "[CV 5/5; 9/120] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=-1319.301 total time=   0.2s\n",
      "[CV 1/5; 10/120] START learning_rate=0.01, max_depth=4, n_estimators=25.........\n",
      "[CV 1/5; 10/120] END learning_rate=0.01, max_depth=4, n_estimators=25;, score=-1464.587 total time=   0.1s\n",
      "[CV 2/5; 10/120] START learning_rate=0.01, max_depth=4, n_estimators=25.........\n",
      "[CV 2/5; 10/120] END learning_rate=0.01, max_depth=4, n_estimators=25;, score=-1523.710 total time=   0.1s\n",
      "[CV 3/5; 10/120] START learning_rate=0.01, max_depth=4, n_estimators=25.........\n",
      "[CV 3/5; 10/120] END learning_rate=0.01, max_depth=4, n_estimators=25;, score=-1486.577 total time=   0.1s\n",
      "[CV 4/5; 10/120] START learning_rate=0.01, max_depth=4, n_estimators=25.........\n",
      "[CV 4/5; 10/120] END learning_rate=0.01, max_depth=4, n_estimators=25;, score=-1513.567 total time=   0.1s\n",
      "[CV 5/5; 10/120] START learning_rate=0.01, max_depth=4, n_estimators=25.........\n",
      "[CV 5/5; 10/120] END learning_rate=0.01, max_depth=4, n_estimators=25;, score=-1581.072 total time=   0.1s\n",
      "[CV 1/5; 11/120] START learning_rate=0.01, max_depth=4, n_estimators=50.........\n",
      "[CV 1/5; 11/120] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=-1328.553 total time=   0.2s\n",
      "[CV 2/5; 11/120] START learning_rate=0.01, max_depth=4, n_estimators=50.........\n",
      "[CV 2/5; 11/120] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=-1383.628 total time=   0.2s\n",
      "[CV 3/5; 11/120] START learning_rate=0.01, max_depth=4, n_estimators=50.........\n",
      "[CV 3/5; 11/120] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=-1346.354 total time=   0.2s\n",
      "[CV 4/5; 11/120] START learning_rate=0.01, max_depth=4, n_estimators=50.........\n",
      "[CV 4/5; 11/120] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=-1372.973 total time=   0.2s\n",
      "[CV 5/5; 11/120] START learning_rate=0.01, max_depth=4, n_estimators=50.........\n",
      "[CV 5/5; 11/120] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=-1450.102 total time=   0.2s\n",
      "[CV 1/5; 12/120] START learning_rate=0.01, max_depth=4, n_estimators=100........\n",
      "[CV 1/5; 12/120] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-1172.992 total time=   0.3s\n",
      "[CV 2/5; 12/120] START learning_rate=0.01, max_depth=4, n_estimators=100........\n",
      "[CV 2/5; 12/120] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-1217.308 total time=   0.3s\n",
      "[CV 3/5; 12/120] START learning_rate=0.01, max_depth=4, n_estimators=100........\n",
      "[CV 3/5; 12/120] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-1182.342 total time=   0.3s\n",
      "[CV 4/5; 12/120] START learning_rate=0.01, max_depth=4, n_estimators=100........\n",
      "[CV 4/5; 12/120] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-1212.749 total time=   0.4s\n",
      "[CV 5/5; 12/120] START learning_rate=0.01, max_depth=4, n_estimators=100........\n",
      "[CV 5/5; 12/120] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=-1288.346 total time=   0.3s\n",
      "[CV 1/5; 13/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 13/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=25;, score=-1058.370 total time=   0.1s\n",
      "[CV 2/5; 13/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 13/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=25;, score=-1079.033 total time=   0.1s\n",
      "[CV 3/5; 13/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 13/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=25;, score=-1059.274 total time=   0.2s\n",
      "[CV 4/5; 13/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 13/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=25;, score=-1082.582 total time=   0.1s\n",
      "[CV 5/5; 13/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 13/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=25;, score=-1138.744 total time=   0.1s\n",
      "[CV 1/5; 14/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 14/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=50;, score=-1056.401 total time=   0.2s\n",
      "[CV 2/5; 14/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 14/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=50;, score=-1070.727 total time=   0.2s\n",
      "[CV 3/5; 14/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 14/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=50;, score=-1057.038 total time=   0.3s\n",
      "[CV 4/5; 14/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 14/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=50;, score=-1076.752 total time=   0.3s\n",
      "[CV 5/5; 14/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 14/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=50;, score=-1123.238 total time=   0.3s\n",
      "[CV 1/5; 15/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 15/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=100;, score=-1061.344 total time=   0.4s\n",
      "[CV 2/5; 15/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 15/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=100;, score=-1074.970 total time=   0.4s\n",
      "[CV 3/5; 15/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 15/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=100;, score=-1063.949 total time=   0.4s\n",
      "[CV 4/5; 15/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 15/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=100;, score=-1079.115 total time=   0.4s\n",
      "[CV 5/5; 15/120] START learning_rate=0.10888888888888888, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 15/120] END learning_rate=0.10888888888888888, max_depth=None, n_estimators=100;, score=-1125.314 total time=   0.4s\n",
      "[CV 1/5; 16/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 16/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=25;, score=-1089.918 total time=   0.1s\n",
      "[CV 2/5; 16/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 16/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=25;, score=-1119.215 total time=   0.1s\n",
      "[CV 3/5; 16/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 16/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=25;, score=-1093.427 total time=   0.1s\n",
      "[CV 4/5; 16/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 16/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=25;, score=-1125.286 total time=   0.2s\n",
      "[CV 5/5; 16/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 16/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=25;, score=-1182.839 total time=   0.1s\n",
      "[CV 1/5; 17/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 17/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=50;, score=-1060.605 total time=   0.1s\n",
      "[CV 2/5; 17/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 17/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=50;, score=-1078.295 total time=   0.1s\n",
      "[CV 3/5; 17/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 17/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=50;, score=-1060.229 total time=   0.1s\n",
      "[CV 4/5; 17/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 17/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=50;, score=-1088.921 total time=   0.2s\n",
      "[CV 5/5; 17/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 17/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=50;, score=-1135.956 total time=   0.2s\n",
      "[CV 1/5; 18/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 18/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=100;, score=-1058.109 total time=   0.3s\n",
      "[CV 2/5; 18/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 18/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=100;, score=-1071.348 total time=   0.2s\n",
      "[CV 3/5; 18/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 18/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=100;, score=-1056.249 total time=   0.2s\n",
      "[CV 4/5; 18/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 18/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=100;, score=-1083.317 total time=   0.2s\n",
      "[CV 5/5; 18/120] START learning_rate=0.10888888888888888, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 18/120] END learning_rate=0.10888888888888888, max_depth=2, n_estimators=100;, score=-1124.046 total time=   0.2s\n",
      "[CV 1/5; 19/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 19/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=25;, score=-1064.617 total time=   0.2s\n",
      "[CV 2/5; 19/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 19/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=25;, score=-1085.839 total time=   0.1s\n",
      "[CV 3/5; 19/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 19/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=25;, score=-1067.278 total time=   0.1s\n",
      "[CV 4/5; 19/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 19/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=25;, score=-1094.117 total time=   0.1s\n",
      "[CV 5/5; 19/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 19/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=25;, score=-1148.729 total time=   0.1s\n",
      "[CV 1/5; 20/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 20/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=50;, score=-1057.305 total time=   0.2s\n",
      "[CV 2/5; 20/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 20/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=50;, score=-1069.221 total time=   0.1s\n",
      "[CV 3/5; 20/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 20/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=50;, score=-1055.612 total time=   0.2s\n",
      "[CV 4/5; 20/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 20/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=50;, score=-1077.795 total time=   0.1s\n",
      "[CV 5/5; 20/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 20/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=50;, score=-1123.850 total time=   0.2s\n",
      "[CV 1/5; 21/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 21/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=100;, score=-1058.634 total time=   0.3s\n",
      "[CV 2/5; 21/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 21/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=100;, score=-1067.534 total time=   0.3s\n",
      "[CV 3/5; 21/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 21/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=100;, score=-1057.551 total time=   0.3s\n",
      "[CV 4/5; 21/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 21/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=100;, score=-1079.345 total time=   0.3s\n",
      "[CV 5/5; 21/120] START learning_rate=0.10888888888888888, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 21/120] END learning_rate=0.10888888888888888, max_depth=3, n_estimators=100;, score=-1119.755 total time=   0.3s\n",
      "[CV 1/5; 22/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 22/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=25;, score=-1060.932 total time=   0.2s\n",
      "[CV 2/5; 22/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 22/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=25;, score=-1080.888 total time=   0.2s\n",
      "[CV 3/5; 22/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 22/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=25;, score=-1060.929 total time=   0.2s\n",
      "[CV 4/5; 22/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 22/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=25;, score=-1085.063 total time=   0.2s\n",
      "[CV 5/5; 22/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 22/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=25;, score=-1140.887 total time=   0.1s\n",
      "[CV 1/5; 23/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 23/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=50;, score=-1056.268 total time=   0.2s\n",
      "[CV 2/5; 23/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 23/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=50;, score=-1071.027 total time=   0.2s\n",
      "[CV 3/5; 23/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 23/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=50;, score=-1055.107 total time=   0.2s\n",
      "[CV 4/5; 23/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 23/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=50;, score=-1074.933 total time=   0.2s\n",
      "[CV 5/5; 23/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 23/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=50;, score=-1122.857 total time=   0.2s\n",
      "[CV 1/5; 24/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 24/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=100;, score=-1059.045 total time=   0.3s\n",
      "[CV 2/5; 24/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 24/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=100;, score=-1067.938 total time=   0.3s\n",
      "[CV 3/5; 24/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 24/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=100;, score=-1058.119 total time=   0.3s\n",
      "[CV 4/5; 24/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 24/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=100;, score=-1077.256 total time=   0.4s\n",
      "[CV 5/5; 24/120] START learning_rate=0.10888888888888888, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 24/120] END learning_rate=0.10888888888888888, max_depth=4, n_estimators=100;, score=-1121.496 total time=   0.3s\n",
      "[CV 1/5; 25/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 25/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=25;, score=-1058.794 total time=   0.2s\n",
      "[CV 2/5; 25/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 25/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=25;, score=-1072.979 total time=   0.2s\n",
      "[CV 3/5; 25/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 25/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=25;, score=-1058.090 total time=   0.2s\n",
      "[CV 4/5; 25/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 25/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=25;, score=-1077.556 total time=   0.2s\n",
      "[CV 5/5; 25/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 25/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=25;, score=-1123.889 total time=   0.2s\n",
      "[CV 1/5; 26/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 26/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=50;, score=-1064.037 total time=   0.3s\n",
      "[CV 2/5; 26/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 26/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=50;, score=-1078.661 total time=   0.4s\n",
      "[CV 3/5; 26/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 26/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=50;, score=-1067.870 total time=   0.3s\n",
      "[CV 4/5; 26/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 26/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=50;, score=-1081.021 total time=   0.3s\n",
      "[CV 5/5; 26/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 26/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=50;, score=-1124.850 total time=   0.3s\n",
      "[CV 1/5; 27/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 27/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=100;, score=-1074.077 total time=   0.4s\n",
      "[CV 2/5; 27/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 27/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=100;, score=-1088.874 total time=   0.4s\n",
      "[CV 3/5; 27/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 27/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=100;, score=-1072.374 total time=   0.4s\n",
      "[CV 4/5; 27/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 27/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=100;, score=-1093.427 total time=   0.5s\n",
      "[CV 5/5; 27/120] START learning_rate=0.20777777777777778, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 27/120] END learning_rate=0.20777777777777778, max_depth=None, n_estimators=100;, score=-1133.180 total time=   0.4s\n",
      "[CV 1/5; 28/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 28/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=25;, score=-1062.562 total time=   0.1s\n",
      "[CV 2/5; 28/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 28/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=25;, score=-1078.145 total time=   0.2s\n",
      "[CV 3/5; 28/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 28/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=25;, score=-1064.053 total time=   0.1s\n",
      "[CV 4/5; 28/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 28/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=25;, score=-1085.514 total time=   0.1s\n",
      "[CV 5/5; 28/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 28/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=25;, score=-1138.982 total time=   0.2s\n",
      "[CV 1/5; 29/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 29/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=50;, score=-1062.324 total time=   0.2s\n",
      "[CV 2/5; 29/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 29/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=50;, score=-1072.865 total time=   0.2s\n",
      "[CV 3/5; 29/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 29/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=50;, score=-1060.274 total time=   0.2s\n",
      "[CV 4/5; 29/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 29/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=50;, score=-1081.279 total time=   0.2s\n",
      "[CV 5/5; 29/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 29/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=50;, score=-1128.377 total time=   0.2s\n",
      "[CV 1/5; 30/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 30/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=100;, score=-1062.197 total time=   0.3s\n",
      "[CV 2/5; 30/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 30/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=100;, score=-1073.916 total time=   0.3s\n",
      "[CV 3/5; 30/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 30/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=100;, score=-1058.471 total time=   0.3s\n",
      "[CV 4/5; 30/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 30/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=100;, score=-1080.252 total time=   0.3s\n",
      "[CV 5/5; 30/120] START learning_rate=0.20777777777777778, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 30/120] END learning_rate=0.20777777777777778, max_depth=2, n_estimators=100;, score=-1126.115 total time=   0.3s\n",
      "[CV 1/5; 31/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 31/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=25;, score=-1057.366 total time=   0.2s\n",
      "[CV 2/5; 31/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 31/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=25;, score=-1070.523 total time=   0.2s\n",
      "[CV 3/5; 31/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 31/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=25;, score=-1055.623 total time=   0.2s\n",
      "[CV 4/5; 31/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 31/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=25;, score=-1080.069 total time=   0.2s\n",
      "[CV 5/5; 31/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 31/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=25;, score=-1125.156 total time=   0.2s\n",
      "[CV 1/5; 32/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 32/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=50;, score=-1061.197 total time=   0.2s\n",
      "[CV 2/5; 32/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 32/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=50;, score=-1068.997 total time=   0.2s\n",
      "[CV 3/5; 32/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 32/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=50;, score=-1056.038 total time=   0.2s\n",
      "[CV 4/5; 32/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 32/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=50;, score=-1081.813 total time=   0.2s\n",
      "[CV 5/5; 32/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 32/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=50;, score=-1121.053 total time=   0.2s\n",
      "[CV 1/5; 33/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 33/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=100;, score=-1064.615 total time=   0.3s\n",
      "[CV 2/5; 33/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 33/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=100;, score=-1073.970 total time=   0.3s\n",
      "[CV 3/5; 33/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 33/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=100;, score=-1057.660 total time=   0.2s\n",
      "[CV 4/5; 33/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 33/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=100;, score=-1088.109 total time=   0.3s\n",
      "[CV 5/5; 33/120] START learning_rate=0.20777777777777778, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 33/120] END learning_rate=0.20777777777777778, max_depth=3, n_estimators=100;, score=-1126.223 total time=   0.3s\n",
      "[CV 1/5; 34/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 34/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=25;, score=-1057.477 total time=   0.2s\n",
      "[CV 2/5; 34/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 34/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=25;, score=-1074.428 total time=   0.1s\n",
      "[CV 3/5; 34/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 34/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=25;, score=-1055.822 total time=   0.2s\n",
      "[CV 4/5; 34/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 34/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=25;, score=-1077.402 total time=   0.1s\n",
      "[CV 5/5; 34/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 34/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=25;, score=-1122.378 total time=   0.2s\n",
      "[CV 1/5; 35/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 35/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=50;, score=-1059.655 total time=   0.2s\n",
      "[CV 2/5; 35/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 35/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=50;, score=-1071.899 total time=   0.2s\n",
      "[CV 3/5; 35/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 35/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=50;, score=-1059.638 total time=   0.2s\n",
      "[CV 4/5; 35/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 35/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=50;, score=-1078.532 total time=   0.2s\n",
      "[CV 5/5; 35/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 35/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=50;, score=-1119.806 total time=   0.2s\n",
      "[CV 1/5; 36/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 36/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=100;, score=-1063.909 total time=   0.4s\n",
      "[CV 2/5; 36/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 36/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=100;, score=-1077.878 total time=   0.3s\n",
      "[CV 3/5; 36/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 36/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=100;, score=-1063.441 total time=   0.3s\n",
      "[CV 4/5; 36/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 36/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=100;, score=-1090.244 total time=   0.4s\n",
      "[CV 5/5; 36/120] START learning_rate=0.20777777777777778, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 36/120] END learning_rate=0.20777777777777778, max_depth=4, n_estimators=100;, score=-1121.582 total time=   0.3s\n",
      "[CV 1/5; 37/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 37/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=25;, score=-1067.324 total time=   0.2s\n",
      "[CV 2/5; 37/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 37/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=25;, score=-1083.686 total time=   0.2s\n",
      "[CV 3/5; 37/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 37/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=25;, score=-1065.020 total time=   0.1s\n",
      "[CV 4/5; 37/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 37/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=25;, score=-1091.605 total time=   0.2s\n",
      "[CV 5/5; 37/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 37/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=25;, score=-1128.925 total time=   0.2s\n",
      "[CV 1/5; 38/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 38/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=50;, score=-1074.499 total time=   0.2s\n",
      "[CV 2/5; 38/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 38/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=50;, score=-1089.476 total time=   0.3s\n",
      "[CV 3/5; 38/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 38/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=50;, score=-1069.327 total time=   0.2s\n",
      "[CV 4/5; 38/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 38/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=50;, score=-1094.825 total time=   0.2s\n",
      "[CV 5/5; 38/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 38/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=50;, score=-1132.621 total time=   0.3s\n",
      "[CV 1/5; 39/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 39/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=100;, score=-1085.565 total time=   0.5s\n",
      "[CV 2/5; 39/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 39/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=100;, score=-1104.018 total time=   0.4s\n",
      "[CV 3/5; 39/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 39/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=100;, score=-1081.754 total time=   0.4s\n",
      "[CV 4/5; 39/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 39/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=100;, score=-1120.550 total time=   0.4s\n",
      "[CV 5/5; 39/120] START learning_rate=0.30666666666666664, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 39/120] END learning_rate=0.30666666666666664, max_depth=None, n_estimators=100;, score=-1136.790 total time=   0.4s\n",
      "[CV 1/5; 40/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 40/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=25;, score=-1062.974 total time=   0.2s\n",
      "[CV 2/5; 40/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 40/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=25;, score=-1075.816 total time=   0.1s\n",
      "[CV 3/5; 40/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 40/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=25;, score=-1062.525 total time=   0.2s\n",
      "[CV 4/5; 40/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 40/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=25;, score=-1084.366 total time=   0.1s\n",
      "[CV 5/5; 40/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 40/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=25;, score=-1136.889 total time=   0.1s\n",
      "[CV 1/5; 41/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 41/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=50;, score=-1062.497 total time=   0.1s\n",
      "[CV 2/5; 41/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 41/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=50;, score=-1072.548 total time=   0.1s\n",
      "[CV 3/5; 41/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 41/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=50;, score=-1059.690 total time=   0.2s\n",
      "[CV 4/5; 41/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 41/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=50;, score=-1085.061 total time=   0.2s\n",
      "[CV 5/5; 41/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 41/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=50;, score=-1127.606 total time=   0.2s\n",
      "[CV 1/5; 42/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 42/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=100;, score=-1066.762 total time=   0.3s\n",
      "[CV 2/5; 42/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 42/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=100;, score=-1075.646 total time=   0.2s\n",
      "[CV 3/5; 42/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 42/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=100;, score=-1058.912 total time=   0.2s\n",
      "[CV 4/5; 42/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 42/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=100;, score=-1086.801 total time=   0.3s\n",
      "[CV 5/5; 42/120] START learning_rate=0.30666666666666664, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 42/120] END learning_rate=0.30666666666666664, max_depth=2, n_estimators=100;, score=-1127.208 total time=   0.3s\n",
      "[CV 1/5; 43/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 43/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=25;, score=-1064.874 total time=   0.2s\n",
      "[CV 2/5; 43/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 43/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=25;, score=-1077.700 total time=   0.1s\n",
      "[CV 3/5; 43/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 43/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=25;, score=-1058.250 total time=   0.1s\n",
      "[CV 4/5; 43/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 43/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=25;, score=-1079.966 total time=   0.1s\n",
      "[CV 5/5; 43/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 43/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=25;, score=-1123.575 total time=   0.1s\n",
      "[CV 1/5; 44/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 44/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=50;, score=-1068.239 total time=   0.2s\n",
      "[CV 2/5; 44/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 44/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=50;, score=-1077.180 total time=   0.3s\n",
      "[CV 3/5; 44/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 44/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=50;, score=-1061.146 total time=   0.2s\n",
      "[CV 4/5; 44/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 44/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=50;, score=-1085.781 total time=   0.2s\n",
      "[CV 5/5; 44/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 44/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=50;, score=-1122.733 total time=   0.2s\n",
      "[CV 1/5; 45/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 45/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=100;, score=-1070.780 total time=   0.3s\n",
      "[CV 2/5; 45/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 45/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=100;, score=-1082.647 total time=   0.3s\n",
      "[CV 3/5; 45/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 45/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=100;, score=-1071.986 total time=   0.3s\n",
      "[CV 4/5; 45/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 45/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=100;, score=-1090.676 total time=   0.4s\n",
      "[CV 5/5; 45/120] START learning_rate=0.30666666666666664, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 45/120] END learning_rate=0.30666666666666664, max_depth=3, n_estimators=100;, score=-1127.043 total time=   0.4s\n",
      "[CV 1/5; 46/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 46/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=25;, score=-1060.736 total time=   0.2s\n",
      "[CV 2/5; 46/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 46/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=25;, score=-1077.098 total time=   0.1s\n",
      "[CV 3/5; 46/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 46/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=25;, score=-1055.225 total time=   0.2s\n",
      "[CV 4/5; 46/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 46/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=25;, score=-1077.161 total time=   0.1s\n",
      "[CV 5/5; 46/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 46/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=25;, score=-1120.623 total time=   0.2s\n",
      "[CV 1/5; 47/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 47/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=50;, score=-1064.618 total time=   0.2s\n",
      "[CV 2/5; 47/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 47/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=50;, score=-1075.660 total time=   0.2s\n",
      "[CV 3/5; 47/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 47/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=50;, score=-1063.699 total time=   0.3s\n",
      "[CV 4/5; 47/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 47/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=50;, score=-1081.934 total time=   0.2s\n",
      "[CV 5/5; 47/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 47/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=50;, score=-1124.782 total time=   0.2s\n",
      "[CV 1/5; 48/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 48/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=100;, score=-1071.160 total time=   0.3s\n",
      "[CV 2/5; 48/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 48/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=100;, score=-1086.107 total time=   0.4s\n",
      "[CV 3/5; 48/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 48/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=100;, score=-1074.480 total time=   0.4s\n",
      "[CV 4/5; 48/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 48/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=100;, score=-1091.060 total time=   0.3s\n",
      "[CV 5/5; 48/120] START learning_rate=0.30666666666666664, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 48/120] END learning_rate=0.30666666666666664, max_depth=4, n_estimators=100;, score=-1130.506 total time=   0.3s\n",
      "[CV 1/5; 49/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 49/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=25;, score=-1068.056 total time=   0.2s\n",
      "[CV 2/5; 49/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 49/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=25;, score=-1080.069 total time=   0.2s\n",
      "[CV 3/5; 49/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 49/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=25;, score=-1067.087 total time=   0.2s\n",
      "[CV 4/5; 49/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 49/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=25;, score=-1089.803 total time=   0.2s\n",
      "[CV 5/5; 49/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 49/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=25;, score=-1130.806 total time=   0.2s\n",
      "[CV 1/5; 50/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 50/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=50;, score=-1082.855 total time=   0.2s\n",
      "[CV 2/5; 50/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 50/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=50;, score=-1082.042 total time=   0.3s\n",
      "[CV 3/5; 50/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 50/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=50;, score=-1083.568 total time=   0.2s\n",
      "[CV 4/5; 50/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 50/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=50;, score=-1106.031 total time=   0.3s\n",
      "[CV 5/5; 50/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 50/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=50;, score=-1139.496 total time=   0.3s\n",
      "[CV 1/5; 51/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 51/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=100;, score=-1102.494 total time=   0.4s\n",
      "[CV 2/5; 51/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 51/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=100;, score=-1106.003 total time=   0.4s\n",
      "[CV 3/5; 51/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 51/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=100;, score=-1107.038 total time=   0.4s\n",
      "[CV 4/5; 51/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 51/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=100;, score=-1131.993 total time=   0.4s\n",
      "[CV 5/5; 51/120] START learning_rate=0.40555555555555556, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 51/120] END learning_rate=0.40555555555555556, max_depth=None, n_estimators=100;, score=-1151.737 total time=   0.4s\n",
      "[CV 1/5; 52/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 52/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=25;, score=-1063.660 total time=   0.2s\n",
      "[CV 2/5; 52/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 52/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=25;, score=-1084.634 total time=   0.1s\n",
      "[CV 3/5; 52/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 52/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=25;, score=-1058.660 total time=   0.1s\n",
      "[CV 4/5; 52/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 52/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=25;, score=-1088.953 total time=   0.1s\n",
      "[CV 5/5; 52/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 52/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=25;, score=-1130.493 total time=   0.1s\n",
      "[CV 1/5; 53/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 53/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=50;, score=-1064.186 total time=   0.2s\n",
      "[CV 2/5; 53/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 53/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=50;, score=-1078.330 total time=   0.2s\n",
      "[CV 3/5; 53/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 53/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=50;, score=-1059.666 total time=   0.2s\n",
      "[CV 4/5; 53/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 53/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=50;, score=-1082.368 total time=   0.2s\n",
      "[CV 5/5; 53/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 53/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=50;, score=-1126.204 total time=   0.2s\n",
      "[CV 1/5; 54/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 54/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=100;, score=-1067.722 total time=   0.3s\n",
      "[CV 2/5; 54/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 54/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=100;, score=-1079.931 total time=   0.3s\n",
      "[CV 3/5; 54/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 54/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=100;, score=-1059.104 total time=   0.2s\n",
      "[CV 4/5; 54/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 54/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=100;, score=-1086.076 total time=   0.3s\n",
      "[CV 5/5; 54/120] START learning_rate=0.40555555555555556, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 54/120] END learning_rate=0.40555555555555556, max_depth=2, n_estimators=100;, score=-1125.148 total time=   0.3s\n",
      "[CV 1/5; 55/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 55/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=25;, score=-1062.393 total time=   0.2s\n",
      "[CV 2/5; 55/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 55/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=25;, score=-1072.217 total time=   0.2s\n",
      "[CV 3/5; 55/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 55/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=25;, score=-1059.381 total time=   0.2s\n",
      "[CV 4/5; 55/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 55/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=25;, score=-1083.576 total time=   0.2s\n",
      "[CV 5/5; 55/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 55/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=25;, score=-1124.321 total time=   0.2s\n",
      "[CV 1/5; 56/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 56/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=50;, score=-1065.280 total time=   0.2s\n",
      "[CV 2/5; 56/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 56/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=50;, score=-1075.713 total time=   0.3s\n",
      "[CV 3/5; 56/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 56/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=50;, score=-1067.522 total time=   0.2s\n",
      "[CV 4/5; 56/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 56/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=50;, score=-1088.961 total time=   0.2s\n",
      "[CV 5/5; 56/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 56/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=50;, score=-1124.507 total time=   0.2s\n",
      "[CV 1/5; 57/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 57/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=100;, score=-1074.339 total time=   0.3s\n",
      "[CV 2/5; 57/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 57/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=100;, score=-1088.729 total time=   0.3s\n",
      "[CV 3/5; 57/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 57/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=100;, score=-1076.096 total time=   0.3s\n",
      "[CV 4/5; 57/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 57/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=100;, score=-1094.391 total time=   0.3s\n",
      "[CV 5/5; 57/120] START learning_rate=0.40555555555555556, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 57/120] END learning_rate=0.40555555555555556, max_depth=3, n_estimators=100;, score=-1129.041 total time=   0.3s\n",
      "[CV 1/5; 58/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 58/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=25;, score=-1067.110 total time=   0.2s\n",
      "[CV 2/5; 58/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 58/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=25;, score=-1081.502 total time=   0.1s\n",
      "[CV 3/5; 58/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 58/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=25;, score=-1064.118 total time=   0.1s\n",
      "[CV 4/5; 58/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 58/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=25;, score=-1078.560 total time=   0.2s\n",
      "[CV 5/5; 58/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 58/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=25;, score=-1121.917 total time=   0.2s\n",
      "[CV 1/5; 59/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 59/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=50;, score=-1069.695 total time=   0.2s\n",
      "[CV 2/5; 59/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 59/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=50;, score=-1082.702 total time=   0.2s\n",
      "[CV 3/5; 59/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 59/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=50;, score=-1072.930 total time=   0.2s\n",
      "[CV 4/5; 59/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 59/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=50;, score=-1091.676 total time=   0.3s\n",
      "[CV 5/5; 59/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 59/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=50;, score=-1122.637 total time=   0.2s\n",
      "[CV 1/5; 60/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 60/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=100;, score=-1076.504 total time=   0.3s\n",
      "[CV 2/5; 60/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 60/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=100;, score=-1095.822 total time=   0.3s\n",
      "[CV 3/5; 60/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 60/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=100;, score=-1085.351 total time=   0.3s\n",
      "[CV 4/5; 60/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 60/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=100;, score=-1106.251 total time=   0.4s\n",
      "[CV 5/5; 60/120] START learning_rate=0.40555555555555556, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 60/120] END learning_rate=0.40555555555555556, max_depth=4, n_estimators=100;, score=-1129.933 total time=   0.3s\n",
      "[CV 1/5; 61/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 61/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=25;, score=-1072.580 total time=   0.2s\n",
      "[CV 2/5; 61/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 61/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=25;, score=-1096.216 total time=   0.2s\n",
      "[CV 3/5; 61/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 61/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=25;, score=-1084.706 total time=   0.2s\n",
      "[CV 4/5; 61/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 61/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=25;, score=-1094.795 total time=   0.2s\n",
      "[CV 5/5; 61/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 61/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=25;, score=-1125.779 total time=   0.2s\n",
      "[CV 1/5; 62/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 62/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=50;, score=-1103.477 total time=   0.3s\n",
      "[CV 2/5; 62/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 62/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=50;, score=-1117.076 total time=   0.3s\n",
      "[CV 3/5; 62/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 62/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=50;, score=-1096.796 total time=   0.3s\n",
      "[CV 4/5; 62/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 62/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=50;, score=-1125.259 total time=   0.3s\n",
      "[CV 5/5; 62/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 62/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=50;, score=-1138.797 total time=   0.3s\n",
      "[CV 1/5; 63/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 63/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=100;, score=-1124.967 total time=   0.5s\n",
      "[CV 2/5; 63/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 63/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=100;, score=-1144.373 total time=   0.4s\n",
      "[CV 3/5; 63/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 63/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=100;, score=-1112.085 total time=   0.5s\n",
      "[CV 4/5; 63/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 63/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=100;, score=-1165.144 total time=   0.4s\n",
      "[CV 5/5; 63/120] START learning_rate=0.5044444444444445, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 63/120] END learning_rate=0.5044444444444445, max_depth=None, n_estimators=100;, score=-1150.832 total time=   0.5s\n",
      "[CV 1/5; 64/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 64/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=25;, score=-1068.491 total time=   0.2s\n",
      "[CV 2/5; 64/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 64/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=25;, score=-1081.609 total time=   0.1s\n",
      "[CV 3/5; 64/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 64/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=25;, score=-1061.181 total time=   0.2s\n",
      "[CV 4/5; 64/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 64/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=25;, score=-1090.963 total time=   0.2s\n",
      "[CV 5/5; 64/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 64/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=25;, score=-1126.169 total time=   0.2s\n",
      "[CV 1/5; 65/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 65/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=50;, score=-1067.050 total time=   0.2s\n",
      "[CV 2/5; 65/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 65/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=50;, score=-1079.831 total time=   0.2s\n",
      "[CV 3/5; 65/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 65/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=50;, score=-1062.066 total time=   0.2s\n",
      "[CV 4/5; 65/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 65/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=50;, score=-1087.111 total time=   0.2s\n",
      "[CV 5/5; 65/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 65/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=50;, score=-1125.522 total time=   0.2s\n",
      "[CV 1/5; 66/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 66/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=100;, score=-1071.762 total time=   0.3s\n",
      "[CV 2/5; 66/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 66/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=100;, score=-1083.638 total time=   0.3s\n",
      "[CV 3/5; 66/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 66/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=100;, score=-1066.872 total time=   0.2s\n",
      "[CV 4/5; 66/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 66/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=100;, score=-1092.032 total time=   0.3s\n",
      "[CV 5/5; 66/120] START learning_rate=0.5044444444444445, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 66/120] END learning_rate=0.5044444444444445, max_depth=2, n_estimators=100;, score=-1122.724 total time=   0.2s\n",
      "[CV 1/5; 67/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 67/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=25;, score=-1061.566 total time=   0.1s\n",
      "[CV 2/5; 67/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 67/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=25;, score=-1076.164 total time=   0.1s\n",
      "[CV 3/5; 67/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 67/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=25;, score=-1062.939 total time=   0.1s\n",
      "[CV 4/5; 67/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 67/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=25;, score=-1086.469 total time=   0.2s\n",
      "[CV 5/5; 67/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 67/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=25;, score=-1130.719 total time=   0.1s\n",
      "[CV 1/5; 68/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 68/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=50;, score=-1067.792 total time=   0.2s\n",
      "[CV 2/5; 68/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 68/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=50;, score=-1084.642 total time=   0.2s\n",
      "[CV 3/5; 68/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 68/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=50;, score=-1065.213 total time=   0.2s\n",
      "[CV 4/5; 68/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 68/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=50;, score=-1094.879 total time=   0.1s\n",
      "[CV 5/5; 68/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 68/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=50;, score=-1130.748 total time=   0.1s\n",
      "[CV 1/5; 69/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 69/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=100;, score=-1074.346 total time=   0.3s\n",
      "[CV 2/5; 69/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 69/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=100;, score=-1096.807 total time=   0.3s\n",
      "[CV 3/5; 69/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 69/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=100;, score=-1081.511 total time=   0.2s\n",
      "[CV 4/5; 69/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 69/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=100;, score=-1112.335 total time=   0.3s\n",
      "[CV 5/5; 69/120] START learning_rate=0.5044444444444445, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 69/120] END learning_rate=0.5044444444444445, max_depth=3, n_estimators=100;, score=-1130.373 total time=   0.3s\n",
      "[CV 1/5; 70/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 70/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=25;, score=-1062.338 total time=   0.1s\n",
      "[CV 2/5; 70/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 70/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=25;, score=-1085.448 total time=   0.1s\n",
      "[CV 3/5; 70/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 70/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=25;, score=-1070.673 total time=   0.2s\n",
      "[CV 4/5; 70/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 70/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=25;, score=-1082.857 total time=   0.2s\n",
      "[CV 5/5; 70/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 70/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=25;, score=-1124.931 total time=   0.1s\n",
      "[CV 1/5; 71/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 71/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=50;, score=-1070.624 total time=   0.2s\n",
      "[CV 2/5; 71/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 71/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=50;, score=-1087.251 total time=   0.2s\n",
      "[CV 3/5; 71/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 71/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=50;, score=-1075.249 total time=   0.2s\n",
      "[CV 4/5; 71/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 71/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=50;, score=-1086.212 total time=   0.2s\n",
      "[CV 5/5; 71/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 71/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=50;, score=-1129.969 total time=   0.1s\n",
      "[CV 1/5; 72/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 72/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=100;, score=-1086.692 total time=   0.3s\n",
      "[CV 2/5; 72/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 72/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=100;, score=-1108.501 total time=   0.3s\n",
      "[CV 3/5; 72/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 72/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=100;, score=-1096.115 total time=   0.3s\n",
      "[CV 4/5; 72/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 72/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=100;, score=-1112.720 total time=   0.3s\n",
      "[CV 5/5; 72/120] START learning_rate=0.5044444444444445, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 72/120] END learning_rate=0.5044444444444445, max_depth=4, n_estimators=100;, score=-1129.464 total time=   0.3s\n",
      "[CV 1/5; 73/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 73/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=25;, score=-1078.035 total time=   0.1s\n",
      "[CV 2/5; 73/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 73/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=25;, score=-1096.475 total time=   0.2s\n",
      "[CV 3/5; 73/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 73/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=25;, score=-1079.550 total time=   0.1s\n",
      "[CV 4/5; 73/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 73/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=25;, score=-1108.300 total time=   0.2s\n",
      "[CV 5/5; 73/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 73/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=25;, score=-1129.677 total time=   0.2s\n",
      "[CV 1/5; 74/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 74/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=50;, score=-1100.179 total time=   0.4s\n",
      "[CV 2/5; 74/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 74/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=50;, score=-1114.788 total time=   0.3s\n",
      "[CV 3/5; 74/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 74/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=50;, score=-1094.943 total time=   0.3s\n",
      "[CV 4/5; 74/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 74/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=50;, score=-1140.143 total time=   0.2s\n",
      "[CV 5/5; 74/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 74/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=50;, score=-1143.418 total time=   0.2s\n",
      "[CV 1/5; 75/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 75/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=100;, score=-1134.081 total time=   0.5s\n",
      "[CV 2/5; 75/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 75/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=100;, score=-1149.665 total time=   0.4s\n",
      "[CV 3/5; 75/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 75/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=100;, score=-1137.133 total time=   0.4s\n",
      "[CV 4/5; 75/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 75/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=100;, score=-1181.463 total time=   0.4s\n",
      "[CV 5/5; 75/120] START learning_rate=0.6033333333333333, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 75/120] END learning_rate=0.6033333333333333, max_depth=None, n_estimators=100;, score=-1170.922 total time=   0.5s\n",
      "[CV 1/5; 76/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 76/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=25;, score=-1065.818 total time=   0.1s\n",
      "[CV 2/5; 76/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 76/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=25;, score=-1077.076 total time=   0.1s\n",
      "[CV 3/5; 76/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 76/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=25;, score=-1058.576 total time=   0.1s\n",
      "[CV 4/5; 76/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 76/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=25;, score=-1090.447 total time=   0.2s\n",
      "[CV 5/5; 76/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 76/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=25;, score=-1127.276 total time=   0.2s\n",
      "[CV 1/5; 77/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 77/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=50;, score=-1065.291 total time=   0.2s\n",
      "[CV 2/5; 77/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 77/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=50;, score=-1084.857 total time=   0.1s\n",
      "[CV 3/5; 77/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 77/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=50;, score=-1058.639 total time=   0.2s\n",
      "[CV 4/5; 77/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 77/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=50;, score=-1092.402 total time=   0.1s\n",
      "[CV 5/5; 77/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 77/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=50;, score=-1126.217 total time=   0.1s\n",
      "[CV 1/5; 78/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 78/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=100;, score=-1076.528 total time=   0.3s\n",
      "[CV 2/5; 78/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 78/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=100;, score=-1087.917 total time=   0.3s\n",
      "[CV 3/5; 78/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 78/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=100;, score=-1069.414 total time=   0.2s\n",
      "[CV 4/5; 78/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 78/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=100;, score=-1097.702 total time=   0.3s\n",
      "[CV 5/5; 78/120] START learning_rate=0.6033333333333333, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 78/120] END learning_rate=0.6033333333333333, max_depth=2, n_estimators=100;, score=-1128.111 total time=   0.3s\n",
      "[CV 1/5; 79/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 79/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=25;, score=-1065.544 total time=   0.2s\n",
      "[CV 2/5; 79/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 79/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=25;, score=-1081.519 total time=   0.1s\n",
      "[CV 3/5; 79/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 79/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=25;, score=-1067.876 total time=   0.1s\n",
      "[CV 4/5; 79/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 79/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=25;, score=-1096.897 total time=   0.2s\n",
      "[CV 5/5; 79/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 79/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=25;, score=-1136.327 total time=   0.2s\n",
      "[CV 1/5; 80/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 80/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=50;, score=-1074.542 total time=   0.2s\n",
      "[CV 2/5; 80/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 80/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=50;, score=-1086.249 total time=   0.2s\n",
      "[CV 3/5; 80/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 80/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=50;, score=-1077.133 total time=   0.2s\n",
      "[CV 4/5; 80/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 80/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=50;, score=-1102.256 total time=   0.2s\n",
      "[CV 5/5; 80/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 80/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=50;, score=-1136.914 total time=   0.2s\n",
      "[CV 1/5; 81/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 81/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=100;, score=-1088.006 total time=   0.3s\n",
      "[CV 2/5; 81/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 81/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=100;, score=-1096.315 total time=   0.3s\n",
      "[CV 3/5; 81/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 81/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=100;, score=-1090.989 total time=   0.3s\n",
      "[CV 4/5; 81/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 81/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=100;, score=-1108.161 total time=   0.3s\n",
      "[CV 5/5; 81/120] START learning_rate=0.6033333333333333, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 81/120] END learning_rate=0.6033333333333333, max_depth=3, n_estimators=100;, score=-1136.175 total time=   0.4s\n",
      "[CV 1/5; 82/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 82/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=25;, score=-1069.796 total time=   0.2s\n",
      "[CV 2/5; 82/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 82/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=25;, score=-1088.606 total time=   0.2s\n",
      "[CV 3/5; 82/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 82/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=25;, score=-1068.348 total time=   0.2s\n",
      "[CV 4/5; 82/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 82/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=25;, score=-1094.167 total time=   0.2s\n",
      "[CV 5/5; 82/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 82/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=25;, score=-1128.793 total time=   0.1s\n",
      "[CV 1/5; 83/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 83/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=50;, score=-1082.021 total time=   0.2s\n",
      "[CV 2/5; 83/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 83/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=50;, score=-1098.664 total time=   0.2s\n",
      "[CV 3/5; 83/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 83/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=50;, score=-1081.143 total time=   0.2s\n",
      "[CV 4/5; 83/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 83/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=50;, score=-1104.159 total time=   0.3s\n",
      "[CV 5/5; 83/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 83/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=50;, score=-1122.340 total time=   0.2s\n",
      "[CV 1/5; 84/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 84/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=100;, score=-1094.622 total time=   0.3s\n",
      "[CV 2/5; 84/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 84/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=100;, score=-1116.261 total time=   0.3s\n",
      "[CV 3/5; 84/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 84/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=100;, score=-1111.498 total time=   0.3s\n",
      "[CV 4/5; 84/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 84/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=100;, score=-1126.152 total time=   0.3s\n",
      "[CV 5/5; 84/120] START learning_rate=0.6033333333333333, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 84/120] END learning_rate=0.6033333333333333, max_depth=4, n_estimators=100;, score=-1138.125 total time=   0.4s\n",
      "[CV 1/5; 85/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 85/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=25;, score=-1082.622 total time=   0.2s\n",
      "[CV 2/5; 85/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 85/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=25;, score=-1113.653 total time=   0.2s\n",
      "[CV 3/5; 85/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 85/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=25;, score=-1089.369 total time=   0.2s\n",
      "[CV 4/5; 85/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 85/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=25;, score=-1105.562 total time=   0.2s\n",
      "[CV 5/5; 85/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 85/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=25;, score=-1153.460 total time=   0.2s\n",
      "[CV 1/5; 86/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 86/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=50;, score=-1101.495 total time=   0.4s\n",
      "[CV 2/5; 86/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 86/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=50;, score=-1140.375 total time=   0.3s\n",
      "[CV 3/5; 86/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 86/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=50;, score=-1127.385 total time=   0.3s\n",
      "[CV 4/5; 86/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 86/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=50;, score=-1137.346 total time=   0.3s\n",
      "[CV 5/5; 86/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 86/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=50;, score=-1156.387 total time=   0.3s\n",
      "[CV 1/5; 87/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 87/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=100;, score=-1143.251 total time=   0.4s\n",
      "[CV 2/5; 87/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 87/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=100;, score=-1191.911 total time=   0.5s\n",
      "[CV 3/5; 87/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 87/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=100;, score=-1167.498 total time=   0.4s\n",
      "[CV 4/5; 87/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 87/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=100;, score=-1183.888 total time=   0.5s\n",
      "[CV 5/5; 87/120] START learning_rate=0.7022222222222222, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 87/120] END learning_rate=0.7022222222222222, max_depth=None, n_estimators=100;, score=-1181.452 total time=   0.4s\n",
      "[CV 1/5; 88/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 88/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=25;, score=-1073.492 total time=   0.1s\n",
      "[CV 2/5; 88/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 88/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=25;, score=-1080.252 total time=   0.2s\n",
      "[CV 3/5; 88/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 88/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=25;, score=-1061.425 total time=   0.1s\n",
      "[CV 4/5; 88/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 88/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=25;, score=-1087.305 total time=   0.1s\n",
      "[CV 5/5; 88/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 88/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=25;, score=-1131.587 total time=   0.1s\n",
      "[CV 1/5; 89/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 89/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=50;, score=-1066.154 total time=   0.2s\n",
      "[CV 2/5; 89/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 89/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=50;, score=-1084.490 total time=   0.2s\n",
      "[CV 3/5; 89/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 89/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=50;, score=-1064.905 total time=   0.2s\n",
      "[CV 4/5; 89/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 89/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=50;, score=-1092.374 total time=   0.2s\n",
      "[CV 5/5; 89/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 89/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=50;, score=-1129.487 total time=   0.2s\n",
      "[CV 1/5; 90/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 90/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=100;, score=-1072.567 total time=   0.3s\n",
      "[CV 2/5; 90/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 90/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=100;, score=-1094.280 total time=   0.3s\n",
      "[CV 3/5; 90/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 90/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=100;, score=-1077.718 total time=   0.3s\n",
      "[CV 4/5; 90/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 90/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=100;, score=-1096.467 total time=   0.3s\n",
      "[CV 5/5; 90/120] START learning_rate=0.7022222222222222, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 90/120] END learning_rate=0.7022222222222222, max_depth=2, n_estimators=100;, score=-1131.543 total time=   0.3s\n",
      "[CV 1/5; 91/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 91/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=25;, score=-1069.114 total time=   0.2s\n",
      "[CV 2/5; 91/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 91/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=25;, score=-1082.373 total time=   0.2s\n",
      "[CV 3/5; 91/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 91/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=25;, score=-1074.481 total time=   0.2s\n",
      "[CV 4/5; 91/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 91/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=25;, score=-1096.773 total time=   0.2s\n",
      "[CV 5/5; 91/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 91/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=25;, score=-1132.154 total time=   0.2s\n",
      "[CV 1/5; 92/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 92/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=50;, score=-1084.674 total time=   0.2s\n",
      "[CV 2/5; 92/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 92/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=50;, score=-1093.949 total time=   0.2s\n",
      "[CV 3/5; 92/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 92/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=50;, score=-1078.648 total time=   0.1s\n",
      "[CV 4/5; 92/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 92/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=50;, score=-1109.544 total time=   0.1s\n",
      "[CV 5/5; 92/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 92/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=50;, score=-1127.235 total time=   0.2s\n",
      "[CV 1/5; 93/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 93/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=100;, score=-1094.623 total time=   0.2s\n",
      "[CV 2/5; 93/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 93/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=100;, score=-1109.359 total time=   0.3s\n",
      "[CV 3/5; 93/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 93/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=100;, score=-1091.855 total time=   0.2s\n",
      "[CV 4/5; 93/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 93/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=100;, score=-1123.750 total time=   0.3s\n",
      "[CV 5/5; 93/120] START learning_rate=0.7022222222222222, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 93/120] END learning_rate=0.7022222222222222, max_depth=3, n_estimators=100;, score=-1135.618 total time=   0.2s\n",
      "[CV 1/5; 94/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 94/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=25;, score=-1069.621 total time=   0.1s\n",
      "[CV 2/5; 94/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 94/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=25;, score=-1083.628 total time=   0.1s\n",
      "[CV 3/5; 94/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 94/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=25;, score=-1070.939 total time=   0.1s\n",
      "[CV 4/5; 94/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 94/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=25;, score=-1098.597 total time=   0.1s\n",
      "[CV 5/5; 94/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 94/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=25;, score=-1127.601 total time=   0.2s\n",
      "[CV 1/5; 95/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 95/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=50;, score=-1084.615 total time=   0.2s\n",
      "[CV 2/5; 95/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 95/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=50;, score=-1103.677 total time=   0.2s\n",
      "[CV 3/5; 95/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 95/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=50;, score=-1097.687 total time=   0.2s\n",
      "[CV 4/5; 95/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 95/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=50;, score=-1112.070 total time=   0.2s\n",
      "[CV 5/5; 95/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 95/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=50;, score=-1138.101 total time=   0.2s\n",
      "[CV 1/5; 96/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 96/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=100;, score=-1099.328 total time=   0.3s\n",
      "[CV 2/5; 96/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 96/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=100;, score=-1129.577 total time=   0.3s\n",
      "[CV 3/5; 96/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 96/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=100;, score=-1109.646 total time=   0.2s\n",
      "[CV 4/5; 96/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 96/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=100;, score=-1151.111 total time=   0.3s\n",
      "[CV 5/5; 96/120] START learning_rate=0.7022222222222222, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 96/120] END learning_rate=0.7022222222222222, max_depth=4, n_estimators=100;, score=-1152.349 total time=   0.3s\n",
      "[CV 1/5; 97/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=25\n",
      "[CV 1/5; 97/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=25;, score=-1083.222 total time=   0.2s\n",
      "[CV 2/5; 97/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=25\n",
      "[CV 2/5; 97/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=25;, score=-1115.043 total time=   0.1s\n",
      "[CV 3/5; 97/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=25\n",
      "[CV 3/5; 97/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=25;, score=-1087.503 total time=   0.1s\n",
      "[CV 4/5; 97/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=25\n",
      "[CV 4/5; 97/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=25;, score=-1127.732 total time=   0.1s\n",
      "[CV 5/5; 97/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=25\n",
      "[CV 5/5; 97/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=25;, score=-1167.884 total time=   0.2s\n",
      "[CV 1/5; 98/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=50\n",
      "[CV 1/5; 98/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=50;, score=-1127.520 total time=   0.3s\n",
      "[CV 2/5; 98/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=50\n",
      "[CV 2/5; 98/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=50;, score=-1149.172 total time=   0.3s\n",
      "[CV 3/5; 98/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=50\n",
      "[CV 3/5; 98/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=50;, score=-1130.172 total time=   0.2s\n",
      "[CV 4/5; 98/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=50\n",
      "[CV 4/5; 98/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=50;, score=-1160.125 total time=   0.3s\n",
      "[CV 5/5; 98/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=50\n",
      "[CV 5/5; 98/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=50;, score=-1192.783 total time=   0.3s\n",
      "[CV 1/5; 99/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=100\n",
      "[CV 1/5; 99/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=100;, score=-1164.514 total time=   0.5s\n",
      "[CV 2/5; 99/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=100\n",
      "[CV 2/5; 99/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=100;, score=-1198.206 total time=   0.4s\n",
      "[CV 3/5; 99/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=100\n",
      "[CV 3/5; 99/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=100;, score=-1162.142 total time=   0.4s\n",
      "[CV 4/5; 99/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=100\n",
      "[CV 4/5; 99/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=100;, score=-1210.084 total time=   0.4s\n",
      "[CV 5/5; 99/120] START learning_rate=0.8011111111111111, max_depth=None, n_estimators=100\n",
      "[CV 5/5; 99/120] END learning_rate=0.8011111111111111, max_depth=None, n_estimators=100;, score=-1211.125 total time=   0.4s\n",
      "[CV 1/5; 100/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=25\n",
      "[CV 1/5; 100/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=25;, score=-1072.866 total time=   0.1s\n",
      "[CV 2/5; 100/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=25\n",
      "[CV 2/5; 100/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=25;, score=-1079.674 total time=   0.1s\n",
      "[CV 3/5; 100/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=25\n",
      "[CV 3/5; 100/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=25;, score=-1071.162 total time=   0.1s\n",
      "[CV 4/5; 100/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=25\n",
      "[CV 4/5; 100/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=25;, score=-1088.918 total time=   0.1s\n",
      "[CV 5/5; 100/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=25\n",
      "[CV 5/5; 100/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=25;, score=-1131.187 total time=   0.2s\n",
      "[CV 1/5; 101/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=50\n",
      "[CV 1/5; 101/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=50;, score=-1075.688 total time=   0.2s\n",
      "[CV 2/5; 101/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=50\n",
      "[CV 2/5; 101/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=50;, score=-1085.385 total time=   0.1s\n",
      "[CV 3/5; 101/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=50\n",
      "[CV 3/5; 101/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=50;, score=-1073.849 total time=   0.1s\n",
      "[CV 4/5; 101/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=50\n",
      "[CV 4/5; 101/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=50;, score=-1098.474 total time=   0.2s\n",
      "[CV 5/5; 101/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=50\n",
      "[CV 5/5; 101/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=50;, score=-1128.717 total time=   0.1s\n",
      "[CV 1/5; 102/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=100\n",
      "[CV 1/5; 102/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=100;, score=-1078.609 total time=   0.2s\n",
      "[CV 2/5; 102/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=100\n",
      "[CV 2/5; 102/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=100;, score=-1094.228 total time=   0.2s\n",
      "[CV 3/5; 102/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=100\n",
      "[CV 3/5; 102/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=100;, score=-1091.320 total time=   0.2s\n",
      "[CV 4/5; 102/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=100\n",
      "[CV 4/5; 102/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=100;, score=-1107.463 total time=   0.3s\n",
      "[CV 5/5; 102/120] START learning_rate=0.8011111111111111, max_depth=2, n_estimators=100\n",
      "[CV 5/5; 102/120] END learning_rate=0.8011111111111111, max_depth=2, n_estimators=100;, score=-1124.565 total time=   0.2s\n",
      "[CV 1/5; 103/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=25\n",
      "[CV 1/5; 103/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=25;, score=-1073.376 total time=   0.1s\n",
      "[CV 2/5; 103/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=25\n",
      "[CV 2/5; 103/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=25;, score=-1085.133 total time=   0.1s\n",
      "[CV 3/5; 103/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=25\n",
      "[CV 3/5; 103/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=25;, score=-1068.878 total time=   0.1s\n",
      "[CV 4/5; 103/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=25\n",
      "[CV 4/5; 103/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=25;, score=-1090.703 total time=   0.2s\n",
      "[CV 5/5; 103/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=25\n",
      "[CV 5/5; 103/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=25;, score=-1137.477 total time=   0.2s\n",
      "[CV 1/5; 104/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=50\n",
      "[CV 1/5; 104/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=50;, score=-1082.848 total time=   0.2s\n",
      "[CV 2/5; 104/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=50\n",
      "[CV 2/5; 104/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=50;, score=-1088.657 total time=   0.2s\n",
      "[CV 3/5; 104/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=50\n",
      "[CV 3/5; 104/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=50;, score=-1087.259 total time=   0.3s\n",
      "[CV 4/5; 104/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=50\n",
      "[CV 4/5; 104/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=50;, score=-1105.365 total time=   0.2s\n",
      "[CV 5/5; 104/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=50\n",
      "[CV 5/5; 104/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=50;, score=-1139.560 total time=   0.3s\n",
      "[CV 1/5; 105/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=100\n",
      "[CV 1/5; 105/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=100;, score=-1096.470 total time=   0.3s\n",
      "[CV 2/5; 105/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=100\n",
      "[CV 2/5; 105/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=100;, score=-1116.674 total time=   0.3s\n",
      "[CV 3/5; 105/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=100\n",
      "[CV 3/5; 105/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=100;, score=-1111.350 total time=   0.3s\n",
      "[CV 4/5; 105/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=100\n",
      "[CV 4/5; 105/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=100;, score=-1124.599 total time=   0.3s\n",
      "[CV 5/5; 105/120] START learning_rate=0.8011111111111111, max_depth=3, n_estimators=100\n",
      "[CV 5/5; 105/120] END learning_rate=0.8011111111111111, max_depth=3, n_estimators=100;, score=-1143.535 total time=   0.3s\n",
      "[CV 1/5; 106/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=25\n",
      "[CV 1/5; 106/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=25;, score=-1083.805 total time=   0.1s\n",
      "[CV 2/5; 106/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=25\n",
      "[CV 2/5; 106/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=25;, score=-1104.153 total time=   0.1s\n",
      "[CV 3/5; 106/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=25\n",
      "[CV 3/5; 106/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=25;, score=-1084.868 total time=   0.2s\n",
      "[CV 4/5; 106/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=25\n",
      "[CV 4/5; 106/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=25;, score=-1106.319 total time=   0.2s\n",
      "[CV 5/5; 106/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=25\n",
      "[CV 5/5; 106/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=25;, score=-1137.068 total time=   0.2s\n",
      "[CV 1/5; 107/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=50\n",
      "[CV 1/5; 107/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=50;, score=-1106.939 total time=   0.2s\n",
      "[CV 2/5; 107/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=50\n",
      "[CV 2/5; 107/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=50;, score=-1111.727 total time=   0.1s\n",
      "[CV 3/5; 107/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=50\n",
      "[CV 3/5; 107/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=50;, score=-1100.568 total time=   0.3s\n",
      "[CV 4/5; 107/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=50\n",
      "[CV 4/5; 107/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=50;, score=-1137.290 total time=   0.1s\n",
      "[CV 5/5; 107/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=50\n",
      "[CV 5/5; 107/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=50;, score=-1145.508 total time=   0.2s\n",
      "[CV 1/5; 108/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=100\n",
      "[CV 1/5; 108/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=100;, score=-1129.249 total time=   0.3s\n",
      "[CV 2/5; 108/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=100\n",
      "[CV 2/5; 108/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=100;, score=-1135.687 total time=   0.3s\n",
      "[CV 3/5; 108/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=100\n",
      "[CV 3/5; 108/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=100;, score=-1138.083 total time=   0.3s\n",
      "[CV 4/5; 108/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=100\n",
      "[CV 4/5; 108/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=100;, score=-1159.999 total time=   0.3s\n",
      "[CV 5/5; 108/120] START learning_rate=0.8011111111111111, max_depth=4, n_estimators=100\n",
      "[CV 5/5; 108/120] END learning_rate=0.8011111111111111, max_depth=4, n_estimators=100;, score=-1161.733 total time=   0.3s\n",
      "[CV 1/5; 109/120] START learning_rate=0.9, max_depth=None, n_estimators=25......\n",
      "[CV 1/5; 109/120] END learning_rate=0.9, max_depth=None, n_estimators=25;, score=-1112.817 total time=   0.2s\n",
      "[CV 2/5; 109/120] START learning_rate=0.9, max_depth=None, n_estimators=25......\n",
      "[CV 2/5; 109/120] END learning_rate=0.9, max_depth=None, n_estimators=25;, score=-1118.291 total time=   0.2s\n",
      "[CV 3/5; 109/120] START learning_rate=0.9, max_depth=None, n_estimators=25......\n",
      "[CV 3/5; 109/120] END learning_rate=0.9, max_depth=None, n_estimators=25;, score=-1090.527 total time=   0.2s\n",
      "[CV 4/5; 109/120] START learning_rate=0.9, max_depth=None, n_estimators=25......\n",
      "[CV 4/5; 109/120] END learning_rate=0.9, max_depth=None, n_estimators=25;, score=-1132.188 total time=   0.2s\n",
      "[CV 5/5; 109/120] START learning_rate=0.9, max_depth=None, n_estimators=25......\n",
      "[CV 5/5; 109/120] END learning_rate=0.9, max_depth=None, n_estimators=25;, score=-1165.414 total time=   0.2s\n",
      "[CV 1/5; 110/120] START learning_rate=0.9, max_depth=None, n_estimators=50......\n",
      "[CV 1/5; 110/120] END learning_rate=0.9, max_depth=None, n_estimators=50;, score=-1159.401 total time=   0.4s\n",
      "[CV 2/5; 110/120] START learning_rate=0.9, max_depth=None, n_estimators=50......\n",
      "[CV 2/5; 110/120] END learning_rate=0.9, max_depth=None, n_estimators=50;, score=-1159.345 total time=   0.3s\n",
      "[CV 3/5; 110/120] START learning_rate=0.9, max_depth=None, n_estimators=50......\n",
      "[CV 3/5; 110/120] END learning_rate=0.9, max_depth=None, n_estimators=50;, score=-1129.207 total time=   0.3s\n",
      "[CV 4/5; 110/120] START learning_rate=0.9, max_depth=None, n_estimators=50......\n",
      "[CV 4/5; 110/120] END learning_rate=0.9, max_depth=None, n_estimators=50;, score=-1177.216 total time=   0.3s\n",
      "[CV 5/5; 110/120] START learning_rate=0.9, max_depth=None, n_estimators=50......\n",
      "[CV 5/5; 110/120] END learning_rate=0.9, max_depth=None, n_estimators=50;, score=-1201.255 total time=   0.3s\n",
      "[CV 1/5; 111/120] START learning_rate=0.9, max_depth=None, n_estimators=100.....\n",
      "[CV 1/5; 111/120] END learning_rate=0.9, max_depth=None, n_estimators=100;, score=-1202.081 total time=   0.4s\n",
      "[CV 2/5; 111/120] START learning_rate=0.9, max_depth=None, n_estimators=100.....\n",
      "[CV 2/5; 111/120] END learning_rate=0.9, max_depth=None, n_estimators=100;, score=-1225.565 total time=   0.4s\n",
      "[CV 3/5; 111/120] START learning_rate=0.9, max_depth=None, n_estimators=100.....\n",
      "[CV 3/5; 111/120] END learning_rate=0.9, max_depth=None, n_estimators=100;, score=-1190.086 total time=   0.4s\n",
      "[CV 4/5; 111/120] START learning_rate=0.9, max_depth=None, n_estimators=100.....\n",
      "[CV 4/5; 111/120] END learning_rate=0.9, max_depth=None, n_estimators=100;, score=-1230.420 total time=   0.5s\n",
      "[CV 5/5; 111/120] START learning_rate=0.9, max_depth=None, n_estimators=100.....\n",
      "[CV 5/5; 111/120] END learning_rate=0.9, max_depth=None, n_estimators=100;, score=-1232.759 total time=   0.4s\n",
      "[CV 1/5; 112/120] START learning_rate=0.9, max_depth=2, n_estimators=25.........\n",
      "[CV 1/5; 112/120] END learning_rate=0.9, max_depth=2, n_estimators=25;, score=-1083.172 total time=   0.1s\n",
      "[CV 2/5; 112/120] START learning_rate=0.9, max_depth=2, n_estimators=25.........\n",
      "[CV 2/5; 112/120] END learning_rate=0.9, max_depth=2, n_estimators=25;, score=-1084.328 total time=   0.1s\n",
      "[CV 3/5; 112/120] START learning_rate=0.9, max_depth=2, n_estimators=25.........\n",
      "[CV 3/5; 112/120] END learning_rate=0.9, max_depth=2, n_estimators=25;, score=-1072.686 total time=   0.2s\n",
      "[CV 4/5; 112/120] START learning_rate=0.9, max_depth=2, n_estimators=25.........\n",
      "[CV 4/5; 112/120] END learning_rate=0.9, max_depth=2, n_estimators=25;, score=-1098.564 total time=   0.2s\n",
      "[CV 5/5; 112/120] START learning_rate=0.9, max_depth=2, n_estimators=25.........\n",
      "[CV 5/5; 112/120] END learning_rate=0.9, max_depth=2, n_estimators=25;, score=-1130.653 total time=   0.1s\n",
      "[CV 1/5; 113/120] START learning_rate=0.9, max_depth=2, n_estimators=50.........\n",
      "[CV 1/5; 113/120] END learning_rate=0.9, max_depth=2, n_estimators=50;, score=-1090.032 total time=   0.2s\n",
      "[CV 2/5; 113/120] START learning_rate=0.9, max_depth=2, n_estimators=50.........\n",
      "[CV 2/5; 113/120] END learning_rate=0.9, max_depth=2, n_estimators=50;, score=-1085.389 total time=   0.2s\n",
      "[CV 3/5; 113/120] START learning_rate=0.9, max_depth=2, n_estimators=50.........\n",
      "[CV 3/5; 113/120] END learning_rate=0.9, max_depth=2, n_estimators=50;, score=-1072.783 total time=   0.2s\n",
      "[CV 4/5; 113/120] START learning_rate=0.9, max_depth=2, n_estimators=50.........\n",
      "[CV 4/5; 113/120] END learning_rate=0.9, max_depth=2, n_estimators=50;, score=-1105.165 total time=   0.2s\n",
      "[CV 5/5; 113/120] START learning_rate=0.9, max_depth=2, n_estimators=50.........\n",
      "[CV 5/5; 113/120] END learning_rate=0.9, max_depth=2, n_estimators=50;, score=-1133.260 total time=   0.1s\n",
      "[CV 1/5; 114/120] START learning_rate=0.9, max_depth=2, n_estimators=100........\n",
      "[CV 1/5; 114/120] END learning_rate=0.9, max_depth=2, n_estimators=100;, score=-1090.832 total time=   0.3s\n",
      "[CV 2/5; 114/120] START learning_rate=0.9, max_depth=2, n_estimators=100........\n",
      "[CV 2/5; 114/120] END learning_rate=0.9, max_depth=2, n_estimators=100;, score=-1095.919 total time=   0.3s\n",
      "[CV 3/5; 114/120] START learning_rate=0.9, max_depth=2, n_estimators=100........\n",
      "[CV 3/5; 114/120] END learning_rate=0.9, max_depth=2, n_estimators=100;, score=-1090.704 total time=   0.3s\n",
      "[CV 4/5; 114/120] START learning_rate=0.9, max_depth=2, n_estimators=100........\n",
      "[CV 4/5; 114/120] END learning_rate=0.9, max_depth=2, n_estimators=100;, score=-1109.587 total time=   0.2s\n",
      "[CV 5/5; 114/120] START learning_rate=0.9, max_depth=2, n_estimators=100........\n",
      "[CV 5/5; 114/120] END learning_rate=0.9, max_depth=2, n_estimators=100;, score=-1133.596 total time=   0.3s\n",
      "[CV 1/5; 115/120] START learning_rate=0.9, max_depth=3, n_estimators=25.........\n",
      "[CV 1/5; 115/120] END learning_rate=0.9, max_depth=3, n_estimators=25;, score=-1071.978 total time=   0.1s\n",
      "[CV 2/5; 115/120] START learning_rate=0.9, max_depth=3, n_estimators=25.........\n",
      "[CV 2/5; 115/120] END learning_rate=0.9, max_depth=3, n_estimators=25;, score=-1089.950 total time=   0.2s\n",
      "[CV 3/5; 115/120] START learning_rate=0.9, max_depth=3, n_estimators=25.........\n",
      "[CV 3/5; 115/120] END learning_rate=0.9, max_depth=3, n_estimators=25;, score=-1068.104 total time=   0.2s\n",
      "[CV 4/5; 115/120] START learning_rate=0.9, max_depth=3, n_estimators=25.........\n",
      "[CV 4/5; 115/120] END learning_rate=0.9, max_depth=3, n_estimators=25;, score=-1105.173 total time=   0.2s\n",
      "[CV 5/5; 115/120] START learning_rate=0.9, max_depth=3, n_estimators=25.........\n",
      "[CV 5/5; 115/120] END learning_rate=0.9, max_depth=3, n_estimators=25;, score=-1135.831 total time=   0.2s\n",
      "[CV 1/5; 116/120] START learning_rate=0.9, max_depth=3, n_estimators=50.........\n",
      "[CV 1/5; 116/120] END learning_rate=0.9, max_depth=3, n_estimators=50;, score=-1080.161 total time=   0.2s\n",
      "[CV 2/5; 116/120] START learning_rate=0.9, max_depth=3, n_estimators=50.........\n",
      "[CV 2/5; 116/120] END learning_rate=0.9, max_depth=3, n_estimators=50;, score=-1105.871 total time=   0.2s\n",
      "[CV 3/5; 116/120] START learning_rate=0.9, max_depth=3, n_estimators=50.........\n",
      "[CV 3/5; 116/120] END learning_rate=0.9, max_depth=3, n_estimators=50;, score=-1103.378 total time=   0.2s\n",
      "[CV 4/5; 116/120] START learning_rate=0.9, max_depth=3, n_estimators=50.........\n",
      "[CV 4/5; 116/120] END learning_rate=0.9, max_depth=3, n_estimators=50;, score=-1109.836 total time=   0.2s\n",
      "[CV 5/5; 116/120] START learning_rate=0.9, max_depth=3, n_estimators=50.........\n",
      "[CV 5/5; 116/120] END learning_rate=0.9, max_depth=3, n_estimators=50;, score=-1135.482 total time=   0.2s\n",
      "[CV 1/5; 117/120] START learning_rate=0.9, max_depth=3, n_estimators=100........\n",
      "[CV 1/5; 117/120] END learning_rate=0.9, max_depth=3, n_estimators=100;, score=-1105.594 total time=   0.3s\n",
      "[CV 2/5; 117/120] START learning_rate=0.9, max_depth=3, n_estimators=100........\n",
      "[CV 2/5; 117/120] END learning_rate=0.9, max_depth=3, n_estimators=100;, score=-1136.881 total time=   0.3s\n",
      "[CV 3/5; 117/120] START learning_rate=0.9, max_depth=3, n_estimators=100........\n",
      "[CV 3/5; 117/120] END learning_rate=0.9, max_depth=3, n_estimators=100;, score=-1125.081 total time=   0.4s\n",
      "[CV 4/5; 117/120] START learning_rate=0.9, max_depth=3, n_estimators=100........\n",
      "[CV 4/5; 117/120] END learning_rate=0.9, max_depth=3, n_estimators=100;, score=-1140.927 total time=   0.3s\n",
      "[CV 5/5; 117/120] START learning_rate=0.9, max_depth=3, n_estimators=100........\n",
      "[CV 5/5; 117/120] END learning_rate=0.9, max_depth=3, n_estimators=100;, score=-1151.178 total time=   0.3s\n",
      "[CV 1/5; 118/120] START learning_rate=0.9, max_depth=4, n_estimators=25.........\n",
      "[CV 1/5; 118/120] END learning_rate=0.9, max_depth=4, n_estimators=25;, score=-1075.018 total time=   0.1s\n",
      "[CV 2/5; 118/120] START learning_rate=0.9, max_depth=4, n_estimators=25.........\n",
      "[CV 2/5; 118/120] END learning_rate=0.9, max_depth=4, n_estimators=25;, score=-1106.687 total time=   0.2s\n",
      "[CV 3/5; 118/120] START learning_rate=0.9, max_depth=4, n_estimators=25.........\n",
      "[CV 3/5; 118/120] END learning_rate=0.9, max_depth=4, n_estimators=25;, score=-1098.538 total time=   0.2s\n",
      "[CV 4/5; 118/120] START learning_rate=0.9, max_depth=4, n_estimators=25.........\n",
      "[CV 4/5; 118/120] END learning_rate=0.9, max_depth=4, n_estimators=25;, score=-1109.236 total time=   0.2s\n",
      "[CV 5/5; 118/120] START learning_rate=0.9, max_depth=4, n_estimators=25.........\n",
      "[CV 5/5; 118/120] END learning_rate=0.9, max_depth=4, n_estimators=25;, score=-1132.852 total time=   0.2s\n",
      "[CV 1/5; 119/120] START learning_rate=0.9, max_depth=4, n_estimators=50.........\n",
      "[CV 1/5; 119/120] END learning_rate=0.9, max_depth=4, n_estimators=50;, score=-1109.797 total time=   0.2s\n",
      "[CV 2/5; 119/120] START learning_rate=0.9, max_depth=4, n_estimators=50.........\n",
      "[CV 2/5; 119/120] END learning_rate=0.9, max_depth=4, n_estimators=50;, score=-1122.748 total time=   0.2s\n",
      "[CV 3/5; 119/120] START learning_rate=0.9, max_depth=4, n_estimators=50.........\n",
      "[CV 3/5; 119/120] END learning_rate=0.9, max_depth=4, n_estimators=50;, score=-1130.847 total time=   0.2s\n",
      "[CV 4/5; 119/120] START learning_rate=0.9, max_depth=4, n_estimators=50.........\n",
      "[CV 4/5; 119/120] END learning_rate=0.9, max_depth=4, n_estimators=50;, score=-1130.638 total time=   0.2s\n",
      "[CV 5/5; 119/120] START learning_rate=0.9, max_depth=4, n_estimators=50.........\n",
      "[CV 5/5; 119/120] END learning_rate=0.9, max_depth=4, n_estimators=50;, score=-1143.121 total time=   0.3s\n",
      "[CV 1/5; 120/120] START learning_rate=0.9, max_depth=4, n_estimators=100........\n",
      "[CV 1/5; 120/120] END learning_rate=0.9, max_depth=4, n_estimators=100;, score=-1148.045 total time=   0.3s\n",
      "[CV 2/5; 120/120] START learning_rate=0.9, max_depth=4, n_estimators=100........\n",
      "[CV 2/5; 120/120] END learning_rate=0.9, max_depth=4, n_estimators=100;, score=-1157.216 total time=   0.3s\n",
      "[CV 3/5; 120/120] START learning_rate=0.9, max_depth=4, n_estimators=100........\n",
      "[CV 3/5; 120/120] END learning_rate=0.9, max_depth=4, n_estimators=100;, score=-1162.656 total time=   0.4s\n",
      "[CV 4/5; 120/120] START learning_rate=0.9, max_depth=4, n_estimators=100........\n",
      "[CV 4/5; 120/120] END learning_rate=0.9, max_depth=4, n_estimators=100;, score=-1178.981 total time=   0.3s\n",
      "[CV 5/5; 120/120] START learning_rate=0.9, max_depth=4, n_estimators=100........\n",
      "[CV 5/5; 120/120] END learning_rate=0.9, max_depth=4, n_estimators=100;, score=-1171.042 total time=   0.4s\n",
      "-1076.0382460219766\n",
      "{'learning_rate': 0.10888888888888888, 'max_depth': 4, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "############################ Regression with catboost ###################################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "cbgm = CatBoostRegressor(random_state=24, logging_level='Silent')\n",
    "params = {\"max_depth\":[None, 2, 3, 4],\n",
    "              \"n_estimators\": [25, 50, 100],\n",
    "              \"learning_rate\": np.linspace(0.01, 0.9, 10)}\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "#param = {\"alpha\": np.linspace(0.001,5,10),\"l1_ratio\":np.linspace(0.1,0.9,9)}\n",
    "\n",
    "gcv_cat = GridSearchCV(cbgm,cv = kfold, param_grid=params,scoring=\"neg_root_mean_squared_error\", verbose=10)\n",
    "gcv_cat.fit(X_train,y_train)\n",
    "print(gcv_cat.best_score_)\n",
    "print(gcv_cat.best_params_)\n",
    "#cbgm.fit(X_train,y_train)\n",
    "y_pred = gcv_cat.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CatBoostRegressor in module catboost.core:\n",
      "\n",
      "class CatBoostRegressor(CatBoost)\n",
      " |  CatBoostRegressor(iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for CatBoost regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  Like in CatBoostClassifier, except loss_function, classes_count, class_names and class_weights\n",
      " |  \n",
      " |  loss_function : string, [default='RMSE']\n",
      " |      'RMSE'\n",
      " |      'MAE'\n",
      " |      'Quantile:alpha=value'\n",
      " |      'LogLinQuantile:alpha=value'\n",
      " |      'Poisson'\n",
      " |      'MAPE'\n",
      " |      'Lq:q=value'\n",
      " |      'SurvivalAft:dist=value;scale=value'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CatBoostRegressor\n",
      " |      CatBoost\n",
      " |      _CatBoostBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |      Initialize the CatBoost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : dict\n",
      " |          Parameters for CatBoost.\n",
      " |          If  None, all params are set to their defaults.\n",
      " |          If  dict, overriding parameters present in dict.\n",
      " |  \n",
      " |  fit(self, X, y=None, cat_features=None, text_features=None, embedding_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, plot_file=None, column_description=None, verbose_eval=None, metric_period=None, silent=None, early_stopping_rounds=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, init_model=None, callbacks=None, log_cout=None, log_cerr=None)\n",
      " |      Fit the CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with numerical values.\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cat_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Categ columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      text_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Text columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      embedding_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Embedding columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      sample_weight : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Instance weights, 1 dimensional array like.\n",
      " |      \n",
      " |      baseline : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving 2 dimensional array like data.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      use_best_model : bool, optional (default=None)\n",
      " |          Flag to use best model\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      metric_period : int\n",
      " |          Frequency of evaluating metrics.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      silent : bool\n",
      " |          If silent is True, logging_level is set to Silent.\n",
      " |          If silent is False, logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file (requires installed plotly)\n",
      " |      \n",
      " |      verbose_eval : bool or int\n",
      " |          Synonym for verbose. Only one of these parameters should be set.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          Activates Iter overfitting detector with od_wait set to early_stopping_rounds.\n",
      " |      \n",
      " |      save_snapshot : bool, [default=None]\n",
      " |          Enable progress snapshotting for restoring progress after crashes or interruptions\n",
      " |      \n",
      " |      snapshot_file : string or pathlib.Path, [default=None]\n",
      " |          Learn progress snapshot file path, if None will use default filename\n",
      " |      \n",
      " |      snapshot_interval: int, [default=600]\n",
      " |          Interval between saving snapshots (seconds)\n",
      " |      \n",
      " |      init_model : CatBoost class or string or pathlib.Path, [default=None]\n",
      " |          Continue training starting from the existing model.\n",
      " |          If this parameter is a string or pathlib.Path, load initial model from the path specified by this string.\n",
      " |      \n",
      " |      callbacks : list, optional (default=None)\n",
      " |          List of callback objects that are applied at end of each iteration.\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : CatBoost\n",
      " |  \n",
      " |  predict(self, data, prediction_type=None, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None, task_type='CPU')\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='RawFormulaVal')\n",
      " |          Can be:\n",
      " |          - 'RawFormulaVal' : return raw formula value.\n",
      " |          - 'Exponent' : return Exponent of raw formula value.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          If data is for a single object, the return value is single float formula return value\n",
      " |          otherwise one-dimensional numpy.ndarray of formula return values for each object.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Calculate R^2.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          Data to apply model on.\n",
      " |      y : list or numpy.ndarray\n",
      " |          True labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      R^2 : float\n",
      " |  \n",
      " |  staged_predict(self, data, prediction_type='RawFormulaVal', ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      " |      Predict target at each stage for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : generator for each iteration that generates:\n",
      " |          If data is for a single object, the return value is single float formula return value\n",
      " |          otherwise one-dimensional numpy.ndarray of formula return values for each object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from CatBoost:\n",
      " |  \n",
      " |  calc_feature_statistics(self, data, target=None, feature=None, prediction_type=None, cat_feature_values=None, plot=True, max_cat_features_on_plot=10, thread_count=-1, plot_file=None)\n",
      " |      Get statistics for the feature using the model, dataset and target.\n",
      " |      To use this function, you should install plotly.\n",
      " |      \n",
      " |      The catboost model has borders for the float features used in it. The borders divide\n",
      " |      feature values into bins, and the model's prediction depends on the number of the bin where the\n",
      " |      feature value falls in.\n",
      " |      \n",
      " |      For float features this function takes model's borders and computes\n",
      " |      1) Mean target value for every bin;\n",
      " |      2) Mean model prediction for every bin;\n",
      " |      3) The number of objects in dataset which fall into each bin;\n",
      " |      4) Predictions on varying feature. For every object, varies the feature value\n",
      " |      so that it falls into bin #0, bin #1, ... and counts model predictions.\n",
      " |      Then counts average prediction for each bin.\n",
      " |      \n",
      " |      For categorical features (only one-hot supported) does the same, but takes feature values\n",
      " |      provided in cat_feature_values instead of borders.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost. Pool or dict {'pool_name': pool} if you want several pools\n",
      " |          Data to compute statistics on\n",
      " |      target: numpy.ndarray or pandas.Series or dict {'pool_name': target} if you want several pools or None\n",
      " |          Target corresponding to data\n",
      " |          Use only if data is not catboost.Pool.\n",
      " |      feature: None, int, string, or list of int or strings\n",
      " |          Features indexes or names in pd.DataFrame for which you want to get statistics.\n",
      " |          None, if you need statistics for all features.\n",
      " |      prediction_type: str\n",
      " |          Prediction type used for counting mean_prediction: 'Class', 'Probability' or 'RawFormulaVal'.\n",
      " |          If not specified, is derived from the model.\n",
      " |      cat_feature_values: list or numpy.ndarray or pandas.Series or\n",
      " |                          dict: int or string to list or numpy.ndarray or pandas.Series\n",
      " |          Contains categorical feature values you need to get statistics on.\n",
      " |          Use dict, when parameter 'feature' is a list to specify cat values for different features.\n",
      " |          When parameter 'feature' is int or str, you can just pass list of cat values.\n",
      " |      plot: bool\n",
      " |          Plot statistics.\n",
      " |      max_cat_features_on_plot: int\n",
      " |          If categorical feature takes more than max_cat_features_on_plot different unique values,\n",
      " |          output result on several plots, not more than max_cat_features_on_plot feature values on each.\n",
      " |          Used only if plot=True or plot_file is not None.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use for getting statistics.\n",
      " |      plot_file: str\n",
      " |          Output file for plot statistics.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict if parameter 'feature' is int or string, else dict of dicts:\n",
      " |          For each unique feature contain\n",
      " |          python dict with binarized feature statistics.\n",
      " |          For float feature, includes\n",
      " |                  'borders' -- borders for the specified feature in model\n",
      " |                  'binarized_feature' -- numbers of bins where feature values fall\n",
      " |                  'mean_target' -- mean value of target over each bin\n",
      " |                  'mean_prediction' -- mean value of model prediction over each bin\n",
      " |                  'objects_per_bin' -- number of objects per bin\n",
      " |                  'predictions_on_varying_feature' -- averaged over dataset predictions for\n",
      " |                  varying feature (see above)\n",
      " |          For one-hot feature, returns the same, but with 'cat_values' instead of 'borders'\n",
      " |  \n",
      " |  calc_leaf_indexes(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=False)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool (default=False)\n",
      " |          Enable debug logging level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : 2-dimensional numpy.ndarray of numpy.uint32 with shape (object count, ntree_end - ntree_start).\n",
      " |          i-th row is an array of leaf indexes for i-th object.\n",
      " |  \n",
      " |  compare(self, model, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Draw train and eval errors in Jupyter notebook for both models\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model: CatBoost model\n",
      " |          Another model to draw metrics\n",
      " |      \n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |  \n",
      " |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      " |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |          Same as in eval_metrics except data\n",
      " |      Returns\n",
      " |      -------\n",
      " |          BatchMetricCalcer object\n",
      " |      \n",
      " |      Usage example\n",
      " |      -------\n",
      " |      # Large dataset is partitioned into parts [part1, part2]\n",
      " |      model.fit(params)\n",
      " |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      " |      batch_calcer.add(part1)\n",
      " |      batch_calcer.add(part2)\n",
      " |      metrics = batch_calcer.eval_metrics()\n",
      " |  \n",
      " |  drop_unused_features(self)\n",
      " |      Drop unused features information from model\n",
      " |  \n",
      " |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Calculate metrics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      " |  \n",
      " |  get_all_params(self)\n",
      " |      Get all params (specified by user and default params) that were set in training from CatBoost model.\n",
      " |      Full parameters documentation could be found here: https://catboost.ai/docs/concepts/python-reference_parameters-list.html\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_borders(self)\n",
      " |      Return map feature_index: borders for float features.\n",
      " |  \n",
      " |  get_cat_feature_indices(self)\n",
      " |  \n",
      " |  get_embedding_feature_indices(self)\n",
      " |  \n",
      " |  get_feature_importance(self, data=None, type=<EFstrType.FeatureImportance: 2>, prettified=False, thread_count=-1, verbose=False, fstr_type=None, shap_mode='Auto', model_output='Raw', interaction_indices=None, shap_calc_type='Regular', reference_data=None, sage_n_samples=128, sage_batch_size=512, sage_detect_convergence=True, log_cout=None, log_cerr=None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data :\n",
      " |          Data to get feature importance.\n",
      " |          If type in ('LossFunctionChange', 'ShapValues', 'ShapInteractionValues') data must of Pool type.\n",
      " |              For every object in this dataset feature importances will be calculated.\n",
      " |          if type == 'SageValues' data must of Pool type.\n",
      " |              For every feature in this dataset importance will be calculated.\n",
      " |          If type == 'PredictionValuesChange', data is None or a dataset of Pool type\n",
      " |              Dataset specification is needed only in case if the model does not contain leaf weight information (trained with CatBoost v < 0.9).\n",
      " |          If type == 'PredictionDiff' data must contain a matrix of feature values of shape (2, n_features).\n",
      " |              Possible types are catboost.Pool or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData or pandas.SparseDataFrame or scipy.sparse.spmatrix\n",
      " |          If type == 'FeatureImportance'\n",
      " |              See 'PredictionValuesChange' for non-ranking metrics and 'LossFunctionChange' for ranking metrics.\n",
      " |          If type == 'Interaction'\n",
      " |              This parameter is not used.\n",
      " |      \n",
      " |      type : EFstrType or string (converted to EFstrType), optional\n",
      " |                  (default=EFstrType.FeatureImportance)\n",
      " |          Possible values:\n",
      " |              - PredictionValuesChange\n",
      " |                  Calculate score for every feature.\n",
      " |              - LossFunctionChange\n",
      " |                  Calculate score for every feature by loss.\n",
      " |              - FeatureImportance\n",
      " |                  PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics\n",
      " |              - ShapValues\n",
      " |                  Calculate SHAP Values for every object.\n",
      " |              - ShapInteractionValues\n",
      " |                  Calculate SHAP Interaction Values between each pair of features for every object\n",
      " |              - Interaction\n",
      " |                  Calculate pairwise score between every feature.\n",
      " |              - PredictionDiff\n",
      " |                  Calculate most important features explaining difference in predictions for a pair of documents.\n",
      " |              - SageValues\n",
      " |                  Calculate SAGE value for every feature\n",
      " |      \n",
      " |      prettified : bool, optional (default=False)\n",
      " |          change returned data format to the list of (feature_id, importance) pairs sorted by importance\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      fstr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      shap_mode : string, optional (default=\"Auto\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Auto\"\n",
      " |                  Use direct SHAP Values calculation only if data size is smaller than average leaves number\n",
      " |                  (the best of two strategies below is chosen).\n",
      " |              - \"UsePreCalc\"\n",
      " |                  Calculate SHAP Values for every leaf in preprocessing. Final complexity is\n",
      " |                  O(NT(D+F))+O(TL^2 D^2) where N is the number of documents(objects), T - number of trees,\n",
      " |                  D - average tree depth, F - average number of features in tree, L - average number of leaves in tree\n",
      " |                  This is much faster (because of a smaller constant) than direct calculation when N >> L\n",
      " |              - \"NoPreCalc\"\n",
      " |                  Use direct SHAP Values calculation calculation with complexity O(NTLD^2). Direct algorithm\n",
      " |                  is faster when N < L (algorithm from https://arxiv.org/abs/1802.03888)\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=\"Regular\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Regular\"\n",
      " |                  Calculate regular SHAP values\n",
      " |              - \"Approximate\"\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - \"Exact\"\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      interaction_indices : list of int or string (feature_idx_1, feature_idx_2), optional (default=None)\n",
      " |          used only for ShapInteractionValues type\n",
      " |          Calculate SHAP Interaction Values between pair of features feature_idx_1 and feature_idx_2 for every object\n",
      " |      \n",
      " |      reference_data: catboost.Pool or None\n",
      " |          Reference data for Independent Tree SHAP values from https://arxiv.org/abs/1905.04610v1\n",
      " |          if type == 'ShapValues' and reference_data is not None, then Independent Tree SHAP values are calculated\n",
      " |      \n",
      " |      sage_n_samples: int, optional (default=32)\n",
      " |          Number of outer samples used in SAGE values approximation algorithm\n",
      " |      sage_batch_size: int, optional (default=min(512, number of samples in dataset))\n",
      " |          Number of samples used on each step of SAGE values approximation algorithm\n",
      " |      sage_detect_convergence: bool, optional (default=False)\n",
      " |          If set True, sage values calculation will be stopped either when sage values converge\n",
      " |          or when sage_n_samples iterations of algorithm pass\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      depends on type:\n",
      " |          - FeatureImportance\n",
      " |              See PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics.\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=False (default)\n",
      " |              list of length [n_features] with feature_importance values (float) for feature\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=True\n",
      " |              list of length [n_features] with (feature_id (string), feature_importance (float)) pairs, sorted by feature_importance in descending order\n",
      " |          - ShapValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1) with Shap values (float) for (object, feature).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1). For each object it contains Shap values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - ShapInteractionValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1, n_features + 1) with Shap interaction values (float) for (object, feature(i), feature(j)).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1, n_features + 1). For each object it contains Shap interaction values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - Interaction\n",
      " |              list of length [n_features] of 3-element lists of (first_feature_index, second_feature_index, interaction_score (float))\n",
      " |  \n",
      " |  get_object_importance(self, pool, train_pool, top_size=-1, type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1, verbose=False, ostr_type=None, log_cout=None, log_cerr=None)\n",
      " |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      " |      https://arxiv.org/pdf/1802.06640.pdf\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pool : Pool\n",
      " |          The pool for which you want to evaluate the object importances.\n",
      " |      \n",
      " |      train_pool : Pool\n",
      " |          The pool on which the model has been trained.\n",
      " |      \n",
      " |      top_size : int (default=-1)\n",
      " |          Method returns the result of the top_size most important train objects.\n",
      " |          If -1, then the top size is not limited.\n",
      " |      \n",
      " |      type : string, optional (default='Average')\n",
      " |          Possible values:\n",
      " |              - Average (Method returns the mean train objects scores for all input objects)\n",
      " |              - PerObject (Method returns the train objects scores for every input object)\n",
      " |      \n",
      " |      importance_values_sign : string, optional (default='All')\n",
      " |          Method returns only Positive, Negative or All values.\n",
      " |          Possible values:\n",
      " |              - Positive\n",
      " |              - Negative\n",
      " |              - All\n",
      " |      \n",
      " |      update_method : string, optional (default='SinglePoint')\n",
      " |          Possible values:\n",
      " |              - SinglePoint\n",
      " |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      " |              - AllPoints\n",
      " |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      ostr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      " |  \n",
      " |  get_param(self, key)\n",
      " |      Get param value from CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : string\n",
      " |          The key to get param value from.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value :\n",
      " |          The param value of the key, returns None if param do not exist.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get all params from CatBoost model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_text_feature_indices(self)\n",
      " |  \n",
      " |  grid_search(self, param_grid, X, y=None, cv=3, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Exhaustive search over specified parameter values for a model.\n",
      " |      After calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_grid: dict or list of dictionaries\n",
      " |          Dictionary with parameters names (string) as keys and lists of parameter settings\n",
      " |          to try as values, or a list of such dictionaries, in which case the grids spanned by each\n",
      " |          dictionary in the list are explored.\n",
      " |          This enables searching over any sequence of parameter settings.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for final cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  iterate_leaf_indexes(self, data, ntree_start=0, ntree_end=0)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : generator. For each object in pool yields one-dimensional numpy.ndarray of leaf indexes.\n",
      " |  \n",
      " |  load_model(self, fname=None, format='cbm', stream=None, blob=None)\n",
      " |      Load model from a file, stream or blob.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Input file name.\n",
      " |  \n",
      " |  plot_partial_dependence(self, data, features, plot=True, plot_file=None, thread_count=-1)\n",
      " |      To use this function, you should install plotly.\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      features: int, str, list<int>, tuple<int>, list<string>, tuple<string>\n",
      " |          Float features to calculate partial dependence for. Number of features should be 1 or 2.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use. If -1 use maximum available number of threads.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          If number of features is one - 1d numpy array and figure with line plot.\n",
      " |          If number of features is two - 2d numpy array and figure with 2d heatmap.\n",
      " |  \n",
      " |  plot_predictions(self, data, features_to_change, plot=True, plot_file=None)\n",
      " |      To use this function, you should install plotly.\n",
      " |      \n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      features_to_change: list-like with int (for indices) or str (for names) elements\n",
      " |          Numerical features indices or names in `data` for which you want to vary prediction value.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          List of list of predictions for all buckets for all samples in data\n",
      " |  \n",
      " |  plot_tree(self, tree_idx, pool=None)\n",
      " |  \n",
      " |  randomized_search(self, param_distributions, X, y=None, cv=3, n_iter=10, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Randomized search on hyper parameters.\n",
      " |      After calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      In contrast to grid_search, not all parameter values are tried out,\n",
      " |      but rather a fixed number of parameter settings is sampled from the specified distributions.\n",
      " |      The number of parameter settings that are tried is given by n_iter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_distributions: dict\n",
      " |          Dictionary with parameters names (string) as keys and distributions or lists of parameters to try.\n",
      " |          Distributions must provide a rvs method for sampling (such as those from scipy.stats.distributions).\n",
      " |          If a list is given, it is sampled uniformly.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      n_iter: int\n",
      " |          Number of parameter settings that are sampled.\n",
      " |          n_iter trades off runtime vs quality of the solution.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  save_borders(self, fname)\n",
      " |      Save the model borders to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or pathlib.Path\n",
      " |          Output file name.\n",
      " |  \n",
      " |  save_model(self, fname, format='cbm', export_parameters=None, pool=None)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Output file name.\n",
      " |      format : string\n",
      " |          Possible values:\n",
      " |              * 'cbm' for catboost binary format,\n",
      " |              * 'coreml' to export into Apple CoreML format\n",
      " |              * 'onnx' to export into ONNX-ML format\n",
      " |              * 'pmml' to export into PMML format\n",
      " |              * 'cpp' to export as C++ code\n",
      " |              * 'python' to export as Python code.\n",
      " |      export_parameters : dict\n",
      " |          Parameters for CoreML export:\n",
      " |              * prediction_type : string - either 'probability' or 'raw'\n",
      " |              * coreml_description : string\n",
      " |              * coreml_model_version : string\n",
      " |              * coreml_model_author : string\n",
      " |              * coreml_model_license: string\n",
      " |          Parameters for PMML export:\n",
      " |              * pmml_copyright : string\n",
      " |              * pmml_description : string\n",
      " |              * pmml_model_version : string\n",
      " |      pool : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series or catboost.FeaturesData\n",
      " |          Training pool.\n",
      " |  \n",
      " |  select_features(self, X, y=None, eval_set=None, features_for_select=None, num_features_to_select=None, algorithm=None, steps=None, shap_calc_type=None, train_final_model=True, verbose=None, logging_level=None, plot=False, plot_file=None, log_cout=None, log_cerr=None, grouping=None, features_tags_for_select=None, num_features_tags_to_select=None)\n",
      " |      Select best features from pool according to loss value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      features_for_select : str or list of feature indices, names or ranges\n",
      " |          (for grouping = Individual)\n",
      " |          Which features should participate in the selection.\n",
      " |          Format examples:\n",
      " |              - [0, 2, 3, 4, 17]\n",
      " |              - [0, \"2-4\", 17] (both ends in ranges are inclusive)\n",
      " |              - \"0,2-4,20\"\n",
      " |              - [\"Name0\", \"Name2\", \"Name3\", \"Name4\", \"Name20\"]\n",
      " |      \n",
      " |      num_features_to_select : positive int\n",
      " |          (for grouping = Individual)\n",
      " |          How many features to select from features_for_select.\n",
      " |      \n",
      " |      algorithm : EFeaturesSelectionAlgorithm or string, optional (default=RecursiveByShapValues)\n",
      " |          Which algorithm to use for features selection.\n",
      " |          Possible values:\n",
      " |              - RecursiveByPredictionValuesChange\n",
      " |                  Use prediction values change as feature strength, eliminate batch of features at once.\n",
      " |              - RecursiveByLossFunctionChange\n",
      " |                  Use loss function change as feature strength, eliminate batch of features at each step.\n",
      " |              - RecursiveByShapValues\n",
      " |                  Use shap values to estimate loss function change, eliminate features one by one.\n",
      " |      \n",
      " |      steps : positive int, optional (default=1)\n",
      " |          How many steps should be performed. In other words, how many times a full model will be trained.\n",
      " |          More steps give more accurate results.\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=Regular)\n",
      " |          Which method to use for calculation of shap values.\n",
      " |          Possible values:\n",
      " |              - Regular\n",
      " |                  Calculate regular SHAP values\n",
      " |              - Approximate\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - Exact\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      train_final_model : bool, optional (default=True)\n",
      " |          Need to fit model with selected features.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      grouping : EFeaturesSelectionGrouping or string, optional (default=Individual)\n",
      " |          Which grouping to use for features selection.\n",
      " |          Possible values:\n",
      " |              - Individual\n",
      " |                  Select individual features\n",
      " |              - ByTags\n",
      " |                  Select feature groups (marked by tags)\n",
      " |      \n",
      " |      features_tags_for_select : list of strings\n",
      " |          (for grouping = ByTags)\n",
      " |          Which features tags should participate in the selection.\n",
      " |      \n",
      " |      num_features_tags_to_select : positive int\n",
      " |          (for grouping = ByTags)\n",
      " |          How many features tags to select from features_tags_for_select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with fields:\n",
      " |          'selected_features': list of selected features indices\n",
      " |          'eliminated_features': list of eliminated features indices\n",
      " |          'selected_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |          'eliminated_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set parameters into CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : key=value format\n",
      " |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      " |  \n",
      " |  shrink(self, ntree_end, ntree_start=0)\n",
      " |      Shrink the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntree_end: int\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |  \n",
      " |  virtual_ensembles_predict(self, data, prediction_type='VirtEnsembles', ntree_end=0, virtual_ensembles_count=10, thread_count=-1, verbose=None)\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='RawFormulaVal')\n",
      " |          Can be:\n",
      " |          - 'VirtEnsembles': return V (virtual_ensembles_count) predictions.\n",
      " |              k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant.\n",
      " |          - 'TotalUncertainty': see returned predictions format in 'Returns' part\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      virtual_ensembles_count: int, optional (default=10)\n",
      " |          virtual ensembles count for 'TotalUncertainty' and 'VirtEnsembles' prediction types.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool, optional (default=False)\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          (with V as virtual_ensembles_count and T as trees count,\n",
      " |          k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant)\n",
      " |          If data is for a single object, return 1-dimensional array of predictions with size depends on prediction type,\n",
      " |          otherwise return 2-dimensional numpy.ndarray with shape (number_of_objects x size depends on prediction type);\n",
      " |          Returned predictions depends on prediction type:\n",
      " |          If loss-function was RMSEWithUncertainty:\n",
      " |              - 'VirtEnsembles': [mean0, var0, mean1, var1, ..., vark-1].\n",
      " |              - 'TotalUncertainty': [mean_predict, KnowledgeUnc, DataUnc].\n",
      " |          otherwise for regression:\n",
      " |              - 'VirtEnsembles':  [mean0, mean1, ...].\n",
      " |              - 'TotalUncertainty': [mean_predicts, KnowledgeUnc].\n",
      " |          otherwise for binary classification:\n",
      " |              - 'VirtEnsembles':  [ApproxRawFormulaVal0, ApproxRawFormulaVal1, ..., ApproxRawFormulaValk-1].\n",
      " |              - 'TotalUncertainty':  [DataUnc, TotalUnc].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from CatBoost:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, _)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  copy(self)\n",
      " |  \n",
      " |  get_best_iteration(self)\n",
      " |  \n",
      " |  get_best_score(self)\n",
      " |  \n",
      " |  get_evals_result(self)\n",
      " |  \n",
      " |  get_leaf_values(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_values : 1d-array of leaf values for all trees.\n",
      " |      Value corresponding to j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_leaf_weights(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_weights : 1d-array of leaf weights for all trees.\n",
      " |      Weight of j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_metadata(self)\n",
      " |  \n",
      " |  get_n_features_in(self)\n",
      " |  \n",
      " |  get_scale_and_bias(self)\n",
      " |  \n",
      " |  get_test_eval(self)\n",
      " |  \n",
      " |  get_test_evals(self)\n",
      " |  \n",
      " |  get_tree_leaf_counts(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tree_leaf_counts : 1d-array of numpy.uint32 of size tree_count_.\n",
      " |      tree_leaf_counts[i] equals to the number of leafs in i-th tree of the ensemble.\n",
      " |  \n",
      " |  is_fitted(self)\n",
      " |  \n",
      " |  set_feature_names(self, feature_names)\n",
      " |      Sets feature names equal to feature_names\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      feature_names: 1-d array of strings with new feature names in the same order as in pool\n",
      " |  \n",
      " |  set_leaf_values(self, new_leaf_values)\n",
      " |      Sets values at tree leafs of ensemble equal to new_leaf_values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_leaf_values : 1d-array with new leaf values for all trees.\n",
      " |      It's size should be equal to sum(get_tree_leaf_counts()).\n",
      " |      Value corresponding to j-th leaf of i-th tree should be at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  set_scale_and_bias(self, scale, bias)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from _CatBoostBase:\n",
      " |  \n",
      " |  best_iteration_\n",
      " |  \n",
      " |  best_score_\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  evals_result_\n",
      " |  \n",
      " |  feature_names_\n",
      " |  \n",
      " |  learning_rate_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  random_seed_\n",
      " |  \n",
      " |  tree_count_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CatBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred < 0] =0\n",
    "df = pd.DataFrame({'Item_Identifier':dtest['Item_Identifier'], 'Outlet_Identifier': dtest['Outlet_Identifier'], 'Item_Outlet_Sales':y_pred})\n",
    "df.to_csv(r'D:/CDAC MARCH 2024 AI/PML/assignments/4/submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Item_Identifier':dtest['Item_Identifier'], 'Outlet_Identifier': dtest['Outlet_Identifier'], 'Item_Outlet_Sales':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
